{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51fa9c-eb0e-4efe-8005-492ab0aa0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELLA 1: SYSTEM ARCHITECTURE & DEFINITIONS ---\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize as scipy_minimize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from datetime import datetime\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "# Dependency Check & Import\n",
    "try:\n",
    "    from pymoo.core.problem import ElementwiseProblem\n",
    "    from pymoo.algorithms.moo.moead import MOEAD\n",
    "    from pymoo.optimize import minimize\n",
    "    from pymoo.util.ref_dirs import get_reference_directions\n",
    "    from pymoo.termination import get_termination\n",
    "except ImportError:\n",
    "    raise ImportError(\"Critical Dependency Missing: 'pymoo' is required. Please install it.\")\n",
    "\n",
    "# ESA Problem Module Import\n",
    "try:\n",
    "    import constellations_udp as udp\n",
    "except ImportError:\n",
    "    print(\"Warning: 'constellations_udp.py' not found in the current directory.\")\n",
    "    print(\"Ensure the file exists and the 'data/spoc2/constellations' path is valid.\")\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Detect available cores\n",
    "N_CORES = min(10, multiprocessing.cpu_count() - 1)  # Use 10 cores or available-1\n",
    "print(f\"‚ö° Detected {multiprocessing.cpu_count()} CPU cores\")\n",
    "print(f\"‚ö° Using {N_CORES} cores for parallel processing\")\n",
    "\n",
    "class SpOCConstrainedWrapper(ElementwiseProblem):\n",
    "    \"\"\"\n",
    "    Pymoo Wrapper for the ESA SpOC Challenge Problem.\n",
    "    Implements a Penalty Method to handle the native constraints of the UDP within the MOEA/D algorithm,\n",
    "    which does not support explicit constraint handling in its standard implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.esa_problem = udp.constellation_udp()\n",
    "        lb, ub = self.esa_problem.get_bounds()\n",
    "        # Initialize with n_ieq_constr=0 to bypass MOEA/D assertions.\n",
    "        # Constraints are incorporated directly into the objective function (Penalty).\n",
    "        super().__init__(n_var=20, n_obj=2, n_ieq_constr=0, xl=np.array(lb), xu=np.array(ub))\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        # Integer variable handling via rounding (Gene indices 10-19)\n",
    "        x_eval = x.copy()\n",
    "        x_eval[10:20] = np.round(x_eval[10:20]).astype(int)\n",
    "        \n",
    "        try:\n",
    "            # ESA Simulator Call\n",
    "            f = self.esa_problem.fitness(list(x_eval))\n",
    "            J1, J2 = f[0], f[1]  # Objectives\n",
    "            c1, c2 = f[2], f[3]  # Constraints (<=0 is valid)\n",
    "            \n",
    "            # Adaptive Penalty Method Formulation\n",
    "            # Dynamic penalty based on generation progress\n",
    "            penalty_factor = 1e5  # Fixed large penalty for feasibility dominance\n",
    "            \n",
    "            penalty = 0.0\n",
    "            if c1 > 0:\n",
    "                penalty += penalty_factor + c1 * 1000\n",
    "            if c2 > 0:\n",
    "                penalty += penalty_factor + c2 * 1000\n",
    "            \n",
    "            # Return penalized objectives\n",
    "            out[\"F\"] = [J1 + penalty, J2 + penalty]\n",
    "        except Exception as e:\n",
    "            # Fallback for simulator crashes (e.g., SGP4 propagation errors)\n",
    "            out[\"F\"] = [1e9, 1e9]\n",
    "\n",
    "def train_and_predict_surrogate_global(history_X, history_F, problem_inst, n_candidates=50000):\n",
    "    \"\"\"\n",
    "    Phase 2a: Global Surrogate-Assisted Optimization.\n",
    "    Uses Random Forest to learn the fitness landscape from MOEA/D history.\n",
    "    \"\"\"\n",
    "    print(\" > Initializing GLOBAL Surrogate Model (Random Forest)...\")\n",
    "    \n",
    "    # Filter only valid or near-valid solutions for training stability\n",
    "    valid_mask = np.all(history_F < 5000, axis=1)  # Slightly more relaxed for global\n",
    "    \n",
    "    if np.sum(valid_mask) < 50:  # Need more data for reliable training\n",
    "        print(f\" > Insufficient valid data points ({np.sum(valid_mask)}). Skipping Global Surrogate phase.\")\n",
    "        return []\n",
    "    \n",
    "    X_train = history_X[valid_mask]\n",
    "    y_train = history_F[valid_mask]\n",
    "    \n",
    "    print(f\" > Training on {len(X_train)} valid solutions...\")\n",
    "    \n",
    "    # Enhanced Random Forest with more trees for better accuracy\n",
    "    regr = RandomForestRegressor(\n",
    "        n_estimators=200,  # More trees for better accuracy\n",
    "        max_depth=30,      # Deeper trees for complex landscape\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=N_CORES,  # Use all available cores\n",
    "        verbose=0\n",
    "    )\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    feature_importance = regr.feature_importances_\n",
    "    print(f\" > Top 5 important features: {np.argsort(feature_importance)[-5:][::-1]}\")\n",
    "    \n",
    "    # Candidate Generation - more diverse\n",
    "    candidates = []\n",
    "    n_parents = 50  # Use more parents for diversity\n",
    "    \n",
    "    # Select top parents based on weighted sum\n",
    "    weighted_scores = 0.97 * y_train[:, 0] + 0.03 * y_train[:, 1]\n",
    "    best_parents_idx = np.argsort(weighted_scores)[:n_parents]\n",
    "    parents = X_train[best_parents_idx]\n",
    "    \n",
    "    iterations = n_candidates // len(parents)\n",
    "    for _ in range(iterations):\n",
    "        p = parents[np.random.choice(len(parents))]\n",
    "        # Adaptive perturbation based on feature importance\n",
    "        noise_scale = 0.05 * (1 + feature_importance)  # More perturbation on important features\n",
    "        noise = np.random.normal(0, noise_scale, 20)\n",
    "        child = np.clip(p + noise, problem_inst.xl, problem_inst.xu)\n",
    "        candidates.append(child)\n",
    "    \n",
    "    # Add some purely random candidates for exploration\n",
    "    n_random = n_candidates // 10\n",
    "    for _ in range(n_random):\n",
    "        random_candidate = np.random.uniform(problem_inst.xl, problem_inst.xu)\n",
    "        candidates.append(random_candidate)\n",
    "    \n",
    "    candidates = np.array(candidates)\n",
    "    \n",
    "    # Surrogate Prediction - parallelized\n",
    "    print(f\" > Predicting {len(candidates)} candidates...\")\n",
    "    preds = regr.predict(candidates)\n",
    "    \n",
    "    # Selection Strategy: Pareto front approximation\n",
    "    # First filter by predicted feasibility\n",
    "    predicted_feasible = np.all(preds < 1000, axis=1)\n",
    "    feasible_preds = preds[predicted_feasible]\n",
    "    feasible_candidates = candidates[predicted_feasible]\n",
    "    \n",
    "    if len(feasible_preds) == 0:\n",
    "        print(\" > No feasible predictions. Using weighted sum on all predictions.\")\n",
    "        feasible_preds = preds\n",
    "        feasible_candidates = candidates\n",
    "    \n",
    "    # Weighted sum for initial filtering\n",
    "    weighted_scores = 0.97 * feasible_preds[:, 0] + 0.03 * feasible_preds[:, 1]\n",
    "    top_k = min(50, len(feasible_preds))  # Take more for verification\n",
    "    best_idxs = np.argsort(weighted_scores)[:top_k]\n",
    "    \n",
    "    verified_solutions = []\n",
    "    print(f\" > Verifying top {len(best_idxs)} candidates with physical simulator...\")\n",
    "    \n",
    "    for i, idx in enumerate(best_idxs):\n",
    "        sol = feasible_candidates[idx]\n",
    "        # Integer constraint enforcement\n",
    "        x_check = sol.copy()\n",
    "        x_check[10:20] = np.round(x_check[10:20]).astype(int)\n",
    "        \n",
    "        try:\n",
    "            fit = problem_inst.esa_problem.fitness(list(x_check))\n",
    "            \n",
    "            # Hard Constraint Check\n",
    "            if fit[2] <= 0 and fit[3] <= 0:\n",
    "                verified_solutions.append(sol)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"   Verified {i + 1}/{len(best_idxs)} candidates...\")\n",
    "    \n",
    "    print(f\" > Global Surrogate Phase yielded {len(verified_solutions)} valid improvements.\")\n",
    "    return verified_solutions\n",
    "\n",
    "def train_and_predict_surrogate_local(best_solution, history_X, history_F, problem_inst, n_candidates=20000):\n",
    "    \"\"\"\n",
    "    Phase 2b: Local Surrogate Refinement (Prof's suggestion).\n",
    "    Re-trains surrogate in a local neighborhood of the best solution for fine-grained search.\n",
    "    \"\"\"\n",
    "    print(\" > Initializing LOCAL Surrogate Model (Focused Random Forest)...\")\n",
    "    \n",
    "    # Define local neighborhood (2% of variable range)\n",
    "    ranges = problem_inst.xu - problem_inst.xl\n",
    "    initial_radius = 0.02 * ranges  # Very local: 2% of range\n",
    "    \n",
    "    # Filter solutions within the local neighborhood\n",
    "    distances = np.linalg.norm(history_X - best_solution, axis=1)\n",
    "    neighborhood_mask = distances < np.linalg.norm(initial_radius)\n",
    "    \n",
    "    # If insufficient points, gradually expand neighborhood\n",
    "    expansion_factor = 1.0\n",
    "    while np.sum(neighborhood_mask) < 100 and expansion_factor <= 5.0:\n",
    "        expanded_radius = (0.02 * expansion_factor) * ranges\n",
    "        neighborhood_mask = np.all(\n",
    "            np.abs(history_X - best_solution) <= expanded_radius,\n",
    "            axis=1\n",
    "        )\n",
    "        expansion_factor += 0.5\n",
    "    \n",
    "    print(f\" > Found {np.sum(neighborhood_mask)} solutions in local neighborhood (radius: {expansion_factor*2:.1f}%)\")\n",
    "    \n",
    "    if np.sum(neighborhood_mask) < 30:\n",
    "        print(\" > Insufficient points for local surrogate. Skipping.\")\n",
    "        return []\n",
    "    \n",
    "    X_local = history_X[neighborhood_mask]\n",
    "    y_local = history_F[neighborhood_mask]\n",
    "    \n",
    "    # Train specialized local surrogate\n",
    "    rf_local = RandomForestRegressor(\n",
    "        n_estimators=300,  # More trees for local precision\n",
    "        max_depth=20,      # Shallower trees to prevent overfitting\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=0.7,  # Limit features for local model\n",
    "        random_state=42,\n",
    "        n_jobs=N_CORES,\n",
    "        verbose=0\n",
    "    )\n",
    "    rf_local.fit(X_local, y_local)\n",
    "    \n",
    "    # Generate highly localized candidates\n",
    "    candidates_local = []\n",
    "    \n",
    "    # Strategy 1: Small perturbations around best solution\n",
    "    n_small_perturbations = n_candidates // 2\n",
    "    for _ in range(n_small_perturbations):\n",
    "        # Very small noise for fine-tuning\n",
    "        noise_std = 0.005 * (problem_inst.xu - problem_inst.xl)  # 0.5% of range\n",
    "        noise = np.random.normal(0, noise_std)\n",
    "        child = np.clip(best_solution + noise, problem_inst.xl, problem_inst.xu)\n",
    "        candidates_local.append(child)\n",
    "    \n",
    "    # Strategy 2: Interpolation between best solutions in neighborhood\n",
    "    if len(X_local) > 5:\n",
    "        n_interpolations = n_candidates // 4\n",
    "        top_local_idx = np.argsort(0.97 * y_local[:, 0] + 0.03 * y_local[:, 1])[:5]\n",
    "        top_solutions = X_local[top_local_idx]\n",
    "        \n",
    "        for _ in range(n_interpolations):\n",
    "            # Random convex combination\n",
    "            alpha = np.random.dirichlet(np.ones(len(top_solutions)))\n",
    "            child = np.sum(alpha[:, np.newaxis] * top_solutions, axis=0)\n",
    "            # Add tiny noise\n",
    "            noise = np.random.normal(0, 0.001, 20)\n",
    "            child = np.clip(child + noise, problem_inst.xl, problem_inst.xu)\n",
    "            candidates_local.append(child)\n",
    "    \n",
    "    # Strategy 3: Gaussian Process guided sampling (optional)\n",
    "    n_gp_samples = n_candidates // 4\n",
    "    try:\n",
    "        # Fit Gaussian Process for uncertainty estimation\n",
    "        gp_kernel = Matern(nu=2.5)\n",
    "        gp = GaussianProcessRegressor(kernel=gp_kernel, n_restarts_optimizer=5)\n",
    "        \n",
    "        # Scale outputs for GP\n",
    "        y_mean = np.mean(y_local[:, :2], axis=0)\n",
    "        y_std = np.std(y_local[:, :2], axis=0)\n",
    "        y_scaled = (y_local[:, :2] - y_mean) / (y_std + 1e-8)\n",
    "        \n",
    "        gp.fit(X_local, y_scaled[:, 0])  # Fit on J1 only for speed\n",
    "        \n",
    "        # Use GP to sample promising regions\n",
    "        for _ in range(n_gp_samples):\n",
    "            # Latin hypercube sampling in local region\n",
    "            sample = best_solution.copy()\n",
    "            perturb_mask = np.random.rand(20) < 0.3  # Perturb only 30% of variables\n",
    "            if np.any(perturb_mask):\n",
    "                perturbation = np.random.normal(0, 0.01, 20)\n",
    "                sample[perturb_mask] = np.clip(\n",
    "                    sample[perturb_mask] + perturbation[perturb_mask],\n",
    "                    problem_inst.xl[perturb_mask],\n",
    "                    problem_inst.xu[perturb_mask]\n",
    "                )\n",
    "            candidates_local.append(sample)\n",
    "    except:\n",
    "        # Fallback to random perturbations if GP fails\n",
    "        for _ in range(n_gp_samples):\n",
    "            noise = np.random.normal(0, 0.01, 20)\n",
    "            child = np.clip(best_solution + noise, problem_inst.xl, problem_inst.xu)\n",
    "            candidates_local.append(child)\n",
    "    \n",
    "    candidates_local = np.array(candidates_local)\n",
    "    \n",
    "    # Predict with local surrogate\n",
    "    print(f\" > Predicting {len(candidates_local)} local candidates...\")\n",
    "    preds_local = rf_local.predict(candidates_local)\n",
    "    \n",
    "    # Very aggressive selection for local search\n",
    "    weighted_scores = 0.97 * preds_local[:, 0] + 0.03 * preds_local[:, 1]\n",
    "    top_local_k = min(20, len(candidates_local))\n",
    "    best_local_idxs = np.argsort(weighted_scores)[:top_local_k]\n",
    "    \n",
    "    verified_local = []\n",
    "    print(f\" > Verifying top {len(best_local_idxs)} local candidates...\")\n",
    "    \n",
    "    for idx in best_local_idxs:\n",
    "        sol = candidates_local[idx]\n",
    "        x_check = sol.copy()\n",
    "        x_check[10:20] = np.round(x_check[10:20]).astype(int)\n",
    "        \n",
    "        try:\n",
    "            fit = problem_inst.esa_problem.fitness(list(x_check))\n",
    "            \n",
    "            if fit[2] <= 0 and fit[3] <= 0:\n",
    "                verified_local.append(sol)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\" > Local Surrogate Refinement yielded {len(verified_local)} valid improvements.\")\n",
    "    return verified_local\n",
    "\n",
    "def refine_solution_local_search(start_sol, problem_inst, max_iter=100):\n",
    "    \"\"\"\n",
    "    Phase 3: Enhanced Targeted Local Polishing.\n",
    "    Performs multi-start local optimization for robustness.\n",
    "    \"\"\"\n",
    "    print(\" > Starting Enhanced Local Search (Multi-start Nelder-Mead)...\")\n",
    "    \n",
    "    def objective_wrapper(etas, x_base, fixed_integers):\n",
    "        x = x_base.copy()\n",
    "        # Update only Eta parameters\n",
    "        x[4], x[9] = etas[0], etas[1]\n",
    "        \n",
    "        # Apply fixed integers\n",
    "        x[10:20] = fixed_integers\n",
    "        \n",
    "        try:\n",
    "            f = problem_inst.esa_problem.fitness(list(x))\n",
    "            \n",
    "            # Hard penalty for constraints during polishing\n",
    "            if f[2] > 0 or f[3] > 0:\n",
    "                return 1e9\n",
    "            \n",
    "            # Target Objective: Weighted Sum\n",
    "            return 0.97 * f[0] + 0.03 * f[1]\n",
    "        except:\n",
    "            return 1e9\n",
    "    \n",
    "    # Fix integer variables from best solution\n",
    "    fixed_integers = np.round(start_sol[10:20]).astype(int)\n",
    "    \n",
    "    # Multiple starting points for robustness\n",
    "    start_points = [\n",
    "        [start_sol[4], start_sol[9]],  # Original\n",
    "        [start_sol[4] * 0.9, start_sol[9] * 0.9],\n",
    "        [start_sol[4] * 1.1, start_sol[9] * 0.9],\n",
    "        [start_sol[4] * 0.9, start_sol[9] * 1.1],\n",
    "        [start_sol[4] * 1.1, start_sol[9] * 1.1],\n",
    "    ]\n",
    "    \n",
    "    best_value = float('inf')\n",
    "    best_etas = None\n",
    "    \n",
    "    for i, x0 in enumerate(start_points):\n",
    "        print(f\"   Local search attempt {i + 1}/{len(start_points)}...\")\n",
    "        \n",
    "        try:\n",
    "            res = scipy_minimize(\n",
    "                lambda etas: objective_wrapper(etas, start_sol, fixed_integers),\n",
    "                x0,\n",
    "                method='Nelder-Mead',\n",
    "                bounds=((1.0, 1000.0), (1.0, 1000.0)),\n",
    "                options={\n",
    "                    'maxiter': max_iter // len(start_points),\n",
    "                    'xatol': 1e-6,\n",
    "                    'fatol': 1e-6,\n",
    "                    'adaptive': True\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            if res.success and res.fun < best_value:\n",
    "                best_value = res.fun\n",
    "                best_etas = res.x\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    refined_sol = start_sol.copy()\n",
    "    if best_etas is not None:\n",
    "        refined_sol[4], refined_sol[9] = best_etas[0], best_etas[1]\n",
    "        print(f\"   Local search improved score from {objective_wrapper([start_sol[4], start_sol[9]], start_sol, fixed_integers):.6f} to {best_value:.6f}\")\n",
    "    else:\n",
    "        print(\"   Local search failed to improve solution.\")\n",
    "    \n",
    "    return refined_sol\n",
    "\n",
    "print(\"‚úÖ System Architecture initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335e009-31d9-46f7-98d6-100dc241ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELLA 2: EXECUTION PIPELINE ---\n",
    "\n",
    "# --- HYPERPARAMETERS CONFIGURATION FOR HIGH-PERFORMANCE ---\n",
    "CONFIG = {\n",
    "    \"pop_size\": 500,           # Large population for thorough exploration\n",
    "    \"n_gen\": 2500,            # Extensive generational budget\n",
    "    \"n_neighbors\": 50,         # Larger neighborhood for diversity\n",
    "    \"prob_mating\": 0.85,       # Slightly reduced for more exploration\n",
    "    \"ml_global_candidates\": 100000,  # More candidates for global surrogate\n",
    "    \"ml_local_candidates\": 50000,    # Candidates for local refinement\n",
    "    \"polishing_iter\": 100,     # More iterations for polishing\n",
    "    \"save_history_freq\": 10,   # Save history every 10 generations\n",
    "    \"checkpoint_freq\": 100,    # Save checkpoint every 100 generations\n",
    "}\n",
    "\n",
    "print(f\"=== INITIALIZING HIGH-PERFORMANCE OPTIMIZATION PIPELINE ===\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  ‚Ä¢ Generations: {CONFIG['n_gen']}\")\n",
    "print(f\"  ‚Ä¢ Population: {CONFIG['pop_size']}\")\n",
    "print(f\"  ‚Ä¢ Cores: {N_CORES}\")\n",
    "print(f\"  ‚Ä¢ Global Surrogate Candidates: {CONFIG['ml_global_candidates']:,}\")\n",
    "print(f\"  ‚Ä¢ Local Surrogate Candidates: {CONFIG['ml_local_candidates']:,}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "problem = SpOCConstrainedWrapper()\n",
    "\n",
    "# 1. MOEA/D Initialization with Large Reference Directions\n",
    "print(\"\\n[PHASE 1] Initializing MOEA/D with large population...\")\n",
    "ref_dirs = get_reference_directions(\"das-dennis\", 2, n_partitions=CONFIG['pop_size']-1)\n",
    "\n",
    "algorithm = MOEAD(\n",
    "    ref_dirs,\n",
    "    n_neighbors=CONFIG['n_neighbors'],\n",
    "    prob_neighbor_mating=CONFIG['prob_mating'],\n",
    "    seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "termination = get_termination(\"n_gen\", CONFIG['n_gen'])\n",
    "\n",
    "# --- PHASE 1: EXTENSIVE GLOBAL EVOLUTIONARY SEARCH ---\n",
    "phase1_start = time.time()\n",
    "print(f\"\\n[PHASE 1] Executing MOEA/D for {CONFIG['n_gen']} generations...\")\n",
    "print(f\"  ‚Ä¢ Expected evaluations: {CONFIG['pop_size'] * CONFIG['n_gen']:,}\")\n",
    "print(f\"  ‚Ä¢ Estimated time: {CONFIG['pop_size'] * CONFIG['n_gen'] * 0.1 / 3600:.1f} hours (assuming 0.1s/eval)\")\n",
    "\n",
    "res = minimize(\n",
    "    problem, \n",
    "    algorithm, \n",
    "    termination, \n",
    "    seed=42,\n",
    "    save_history=True,\n",
    "    verbose=True,\n",
    "    callback=None  # Can add custom callback for checkpointing\n",
    ")\n",
    "\n",
    "phase1_time = time.time() - phase1_start\n",
    "print(f\"\\n > MOEA/D Completed in {phase1_time/3600:.2f} hours\")\n",
    "print(f\" > Evaluations performed: {CONFIG['pop_size'] * CONFIG['n_gen']:,}\")\n",
    "print(f\" > Solutions in archive: {len(res.X)}\")\n",
    "\n",
    "# --- PHASE 2a: GLOBAL SURROGATE-AUGMENTED SEARCH ---\n",
    "phase2a_start = time.time()\n",
    "print(f\"\\n[PHASE 2a] Global Surrogate-Augmented Search...\")\n",
    "print(f\"  ‚Ä¢ Using {len(res.X)} evaluated solutions as training data\")\n",
    "print(f\"  ‚Ä¢ Generating {CONFIG['ml_global_candidates']:,} virtual candidates\")\n",
    "\n",
    "ml_solutions_global = train_and_predict_surrogate_global(\n",
    "    res.X, \n",
    "    res.F, \n",
    "    problem, \n",
    "    n_candidates=CONFIG['ml_global_candidates']\n",
    ")\n",
    "\n",
    "phase2a_time = time.time() - phase2a_start\n",
    "print(f\" > Global surrogate completed in {phase2a_time:.1f} seconds\")\n",
    "print(f\" > Found {len(ml_solutions_global)} new valid solutions\")\n",
    "\n",
    "# --- Find current best solution for local refinement ---\n",
    "print(f\"\\n[INTERMEDIATE] Finding current best solution...\")\n",
    "esa_inst = udp.constellation_udp()\n",
    "current_best = None\n",
    "current_best_score = float('inf')\n",
    "\n",
    "# Check MOEA/D solutions\n",
    "for i, sol in enumerate(res.X):\n",
    "    x_check = list(sol.copy())\n",
    "    for k in range(10, 20):\n",
    "        x_check[k] = int(round(x_check[k]))\n",
    "    \n",
    "    try:\n",
    "        fit = esa_inst.fitness(x_check)\n",
    "        if fit[2] <= 0 and fit[3] <= 0:\n",
    "            score = 0.97 * fit[0] + 0.03 * fit[1]\n",
    "            if score < current_best_score:\n",
    "                current_best_score = score\n",
    "                current_best = sol.copy()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Check global surrogate solutions\n",
    "for sol in ml_solutions_global:\n",
    "    x_check = list(sol.copy())\n",
    "    for k in range(10, 20):\n",
    "        x_check[k] = int(round(x_check[k]))\n",
    "    \n",
    "    try:\n",
    "        fit = esa_inst.fitness(x_check)\n",
    "        if fit[2] <= 0 and fit[3] <= 0:\n",
    "            score = 0.97 * fit[0] + 0.03 * fit[1]\n",
    "            if score < current_best_score:\n",
    "                current_best_score = score\n",
    "                current_best = sol.copy()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "if current_best is not None:\n",
    "    print(f\" > Current best score: {current_best_score:.6f}\")\n",
    "else:\n",
    "    print(\" ‚ö†Ô∏è No valid solutions found yet. Using best from MOEA/D.\")\n",
    "    # Use the least infeasible solution\n",
    "    best_idx = np.argmin(res.F.sum(axis=1))\n",
    "    current_best = res.X[best_idx]\n",
    "\n",
    "# --- PHASE 2b: LOCAL SURROGATE REFINEMENT (Prof's Suggestion) ---\n",
    "phase2b_start = time.time()\n",
    "print(f\"\\n[PHASE 2b] Local Surrogate Refinement (Fast neighborhood search)...\")\n",
    "print(f\"  ‚Ä¢ Focusing on neighborhood of best solution\")\n",
    "print(f\"  ‚Ä¢ Reusing {len(res.X)} already-evaluated points\")\n",
    "print(f\"  ‚Ä¢ Generating {CONFIG['ml_local_candidates']:,} focused candidates\")\n",
    "\n",
    "ml_solutions_local = train_and_predict_surrogate_local(\n",
    "    current_best,\n",
    "    res.X,\n",
    "    res.F,\n",
    "    problem,\n",
    "    n_candidates=CONFIG['ml_local_candidates']\n",
    ")\n",
    "\n",
    "phase2b_time = time.time() - phase2b_start\n",
    "print(f\" > Local surrogate completed in {phase2b_time:.1f} seconds\")\n",
    "print(f\" > Found {len(ml_solutions_local)} refined solutions\")\n",
    "\n",
    "# --- Combine all portfolios ---\n",
    "print(f\"\\n[COMBINING PORTFOLIOS]\")\n",
    "full_portfolio = list(res.X) + ml_solutions_global + ml_solutions_local\n",
    "print(f\"  ‚Ä¢ MOEA/D solutions: {len(res.X)}\")\n",
    "print(f\"  ‚Ä¢ Global surrogate: {len(ml_solutions_global)}\")\n",
    "print(f\"  ‚Ä¢ Local refinement: {len(ml_solutions_local)}\")\n",
    "print(f\"  ‚Ä¢ Total portfolio: {len(full_portfolio)}\")\n",
    "\n",
    "# --- PHASE 3: SOLUTION SELECTION & REFINEMENT ---\n",
    "phase3_start = time.time()\n",
    "print(f\"\\n[PHASE 3] Final Selection and Polishing...\")\n",
    "\n",
    "best_score = float('inf')\n",
    "best_candidate = None\n",
    "valid_solutions_count = 0\n",
    "\n",
    "print(f\" > Evaluating {len(full_portfolio)} candidates for final selection...\")\n",
    "\n",
    "for i, sol in enumerate(full_portfolio):\n",
    "    x_check = list(sol.copy())\n",
    "    for k in range(10, 20):\n",
    "        x_check[k] = int(round(x_check[k]))\n",
    "    \n",
    "    try:\n",
    "        fit = esa_inst.fitness(x_check)\n",
    "        is_valid = (fit[2] <= 0 and fit[3] <= 0)\n",
    "        \n",
    "        if is_valid:\n",
    "            valid_solutions_count += 1\n",
    "            score = 0.97 * fit[0] + 0.03 * fit[1]\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_candidate = sol.copy()\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"   Processed {i + 1}/{len(full_portfolio)} candidates...\")\n",
    "\n",
    "if best_candidate is None:\n",
    "    print(\"‚ö†Ô∏è CRITICAL: No feasible solutions in portfolio.\")\n",
    "    print(\" > Using least infeasible solution...\")\n",
    "    # Find solution with smallest constraint violation\n",
    "    min_violation = float('inf')\n",
    "    for sol in full_portfolio:\n",
    "        x_check = list(sol.copy())\n",
    "        for k in range(10, 20):\n",
    "            x_check[k] = int(round(x_check[k]))\n",
    "        try:\n",
    "            fit = esa_inst.fitness(x_check)\n",
    "            violation = max(0, fit[2]) + max(0, fit[3])\n",
    "            if violation < min_violation:\n",
    "                min_violation = violation\n",
    "                best_candidate = sol.copy()\n",
    "                best_score = 0.97 * fit[0] + 0.03 * fit[1]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(f\" > Found {valid_solutions_count} valid solutions\")\n",
    "print(f\" > Best candidate score before polishing: {best_score:.6f}\")\n",
    "\n",
    "# Apply Enhanced Local Search\n",
    "print(\" > Applying Enhanced Local Search (Multi-start)...\")\n",
    "final_solution = refine_solution_local_search(\n",
    "    best_candidate, \n",
    "    esa_inst, \n",
    "    max_iter=CONFIG['polishing_iter']\n",
    ")\n",
    "\n",
    "phase3_time = time.time() - phase3_start\n",
    "print(f\" > Final selection completed in {phase3_time:.1f} seconds\")\n",
    "\n",
    "# --- FINAL EVALUATION ---\n",
    "x_final_eval = list(final_solution.copy())\n",
    "for k in range(10, 20):\n",
    "    x_final_eval[k] = int(round(x_final_eval[k]))\n",
    "\n",
    "final_stats = esa_inst.fitness(x_final_eval)\n",
    "final_score = 0.97 * final_stats[0] + 0.03 * final_stats[1]\n",
    "is_valid = final_stats[2] <= 0 and final_stats[3] <= 0\n",
    "\n",
    "total_time = time.time() - total_start_time\n",
    "\n",
    "# --- COMPREHENSIVE REPORT ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ HIGH-PERFORMANCE OPTIMIZATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Time: {total_time/3600:.2f} hours\")\n",
    "print(f\"Overall Status: {'VALID' if is_valid else 'INVALID'}\")\n",
    "print(f\"Final Composite Score: {final_score:.8f} (Target: Minimize)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"PHASE BREAKDOWN:\")\n",
    "print(f\"  Phase 1 (MOEA/D):         {phase1_time/3600:7.2f} hours\")\n",
    "print(f\"  Phase 2a (Global ML):     {phase2a_time:7.1f} seconds\")\n",
    "print(f\"  Phase 2b (Local ML):      {phase2b_time:7.1f} seconds\")\n",
    "print(f\"  Phase 3 (Selection/Polish): {phase3_time:7.1f} seconds\")\n",
    "print(\"-\" * 80)\n",
    "print(\"PERFORMANCE METRICS:\")\n",
    "print(f\"  Evaluations (Real):       {CONFIG['pop_size'] * CONFIG['n_gen']:,}\")\n",
    "print(f\"  Evaluations (Virtual):    {CONFIG['ml_global_candidates'] + CONFIG['ml_local_candidates']:,}\")\n",
    "print(f\"  Valid Solutions Found:    {valid_solutions_count}\")\n",
    "print(f\"  Speedup from Surrogate:   {(CONFIG['ml_global_candidates'] + CONFIG['ml_local_candidates']) * 0.1 / (phase2a_time + phase2b_time):.1f}x\")\n",
    "print(\"-\" * 80)\n",
    "print(\"FINAL SOLUTION OBJECTIVES:\")\n",
    "print(f\"  J1 (Communication Latency): {final_stats[0]:.8f}\")\n",
    "print(f\"  J2 (Infrastructure Cost):   {final_stats[1]:.8f}\")\n",
    "print(\"-\" * 80)\n",
    "print(\"CONSTRAINTS (<=0 is feasible):\")\n",
    "print(f\"  C1 (Inter-Rover Distance): {final_stats[2]:.6f} km\")\n",
    "print(f\"  C2 (Sat-Collision Safety): {final_stats[3]:.6f} km\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Export final solution\n",
    "final_sol = final_solution\n",
    "\n",
    "# =============================================================================\n",
    "# üìä ENHANCED DATA SAVING WITH CHECKPOINTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíæ SAVING COMPREHENSIVE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect ALL evaluated solutions\n",
    "all_solutions_X = []\n",
    "all_solutions_Y = []\n",
    "all_solutions_metadata = []\n",
    "\n",
    "# 1. Solutions from MOEA/D history (sampled to reduce size)\n",
    "if hasattr(res, 'history') and len(res.history) > 0:\n",
    "    print(f\" > Processing MOEA/D history ({len(res.history)} generations)...\")\n",
    "    # Sample every 10th generation to reduce file size\n",
    "    for gen_idx, algo_snapshot in enumerate(res.history[::10]):\n",
    "        if hasattr(algo_snapshot, 'pop') and algo_snapshot.pop is not None:\n",
    "            pop = algo_snapshot.pop\n",
    "            for ind in pop[::5]:  # Sample population\n",
    "                x_eval = ind.X.copy()\n",
    "                x_eval[10:20] = np.round(x_eval[10:20]).astype(int)\n",
    "                try:\n",
    "                    fit_raw = esa_inst.fitness(list(x_eval))\n",
    "                    all_solutions_X.append(x_eval)\n",
    "                    all_solutions_Y.append(fit_raw)\n",
    "                    all_solutions_metadata.append([gen_idx * 10, 0])  # gen, source\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "# 2. Add global surrogate solutions\n",
    "print(f\" > Adding {len(ml_solutions_global)} global surrogate solutions...\")\n",
    "for sol in ml_solutions_global:\n",
    "    x_eval = sol.copy()\n",
    "    x_eval[10:20] = np.round(x_eval[10:20]).astype(int)\n",
    "    try:\n",
    "        fit_raw = esa_inst.fitness(list(x_eval))\n",
    "        all_solutions_X.append(x_eval)\n",
    "        all_solutions_Y.append(fit_raw)\n",
    "        all_solutions_metadata.append([-1, 1])  # gen=-1, source=global\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 3. Add local refined solutions\n",
    "print(f\" > Adding {len(ml_solutions_local)} local refined solutions...\")\n",
    "for sol in ml_solutions_local:\n",
    "    x_eval = sol.copy()\n",
    "    x_eval[10:20] = np.round(x_eval[10:20]).astype(int)\n",
    "    try:\n",
    "        fit_raw = esa_inst.fitness(list(x_eval))\n",
    "        all_solutions_X.append(x_eval)\n",
    "        all_solutions_Y.append(fit_raw)\n",
    "        all_solutions_metadata.append([-2, 2])  # gen=-2, source=local\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 4. Add final polished solution\n",
    "all_solutions_X.append(final_solution)\n",
    "all_solutions_Y.append(final_stats)\n",
    "all_solutions_metadata.append([-3, 3])  # gen=-3, source=final\n",
    "\n",
    "# Convert to numpy arrays\n",
    "xs = np.array(all_solutions_X)\n",
    "ys = np.array(all_solutions_Y)\n",
    "meta = np.array(all_solutions_metadata)\n",
    "\n",
    "print(f\"‚úì Collected {len(xs)} solutions total\")\n",
    "\n",
    "# Deduplication with tolerance\n",
    "print(\" > Removing duplicates...\")\n",
    "unique_indices = []\n",
    "seen = set()\n",
    "tolerance = 1e-4\n",
    "\n",
    "for i, x in enumerate(xs):\n",
    "    # Round to tolerance for comparison\n",
    "    key = tuple(np.round(x / tolerance) * tolerance)\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        unique_indices.append(i)\n",
    "\n",
    "xs = xs[unique_indices]\n",
    "ys = ys[unique_indices]\n",
    "meta = meta[unique_indices]\n",
    "\n",
    "print(f\"‚úì After deduplication: {len(xs)} unique solutions\")\n",
    "\n",
    "# Create timestamp for filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f'quantcomm_hpc_{timestamp}.npz'\n",
    "\n",
    "# Save comprehensive data\n",
    "np.savez_compressed(\n",
    "    filename,\n",
    "    xs=xs,                    # Decision variables\n",
    "    ys=ys,                    # [J1, J2, c1, c2]\n",
    "    metadata=meta,            # [generation, source]\n",
    "    config=CONFIG,            # Configuration used\n",
    "    final_solution=final_solution,\n",
    "    final_score=final_score,\n",
    "    total_time=total_time,\n",
    "    n_cores=N_CORES\n",
    ")\n",
    "\n",
    "file_size = os.path.getsize(filename) / (1024**2)  # MB\n",
    "print(f\"‚úÖ Results saved to: {filename}\")\n",
    "print(f\"üìä File size: {file_size:.2f} MB\")\n",
    "print(\"\\nüìÅ File contents:\")\n",
    "print(f\"  ‚Ä¢ xs: {xs.shape} - Decision variables\")\n",
    "print(f\"  ‚Ä¢ ys: {ys.shape} - [J1, J2, c1, c2]\")\n",
    "print(f\"  ‚Ä¢ metadata: {meta.shape} - [generation, source]\")\n",
    "print(f\"     - Source codes: 0=MOEA/D, 1=Global, 2=Local, 3=Final\")\n",
    "print(f\"  ‚Ä¢ config: Hyperparameters used\")\n",
    "print(f\"  ‚Ä¢ final_solution: Best solution found\")\n",
    "print(f\"  ‚Ä¢ final_score: {final_score:.8f}\")\n",
    "print(f\"  ‚Ä¢ total_time: {total_time/3600:.2f} hours\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Also save a lightweight version with only Pareto front\n",
    "print(\"\\nüí° Creating lightweight Pareto front file...\")\n",
    "\n",
    "# Extract Pareto front from valid solutions\n",
    "valid_mask = (ys[:, 2] <= 0) & (ys[:, 3] <= 0)\n",
    "if np.any(valid_mask):\n",
    "    valid_xs = xs[valid_mask]\n",
    "    valid_ys = ys[valid_mask]\n",
    "    \n",
    "    # Simple Pareto filter\n",
    "    pareto_mask = np.ones(len(valid_xs), dtype=bool)\n",
    "    for i in range(len(valid_xs)):\n",
    "        for j in range(len(valid_xs)):\n",
    "            if i != j and pareto_mask[i]:\n",
    "                if (valid_ys[j, 0] <= valid_ys[i, 0] and \n",
    "                    valid_ys[j, 1] <= valid_ys[i, 1] and\n",
    "                    (valid_ys[j, 0] < valid_ys[i, 0] or valid_ys[j, 1] < valid_ys[i, 1])):\n",
    "                    pareto_mask[i] = False\n",
    "                    break\n",
    "    \n",
    "    pareto_xs = valid_xs[pareto_mask]\n",
    "    pareto_ys = valid_ys[pareto_mask]\n",
    "    \n",
    "    pareto_filename = f'quantcomm_pareto_{timestamp}.npz'\n",
    "    np.savez_compressed(\n",
    "        pareto_filename,\n",
    "        xs=pareto_xs,\n",
    "        ys=pareto_ys\n",
    "    )\n",
    "    print(f\"‚úÖ Pareto front saved to: {pareto_filename}\")\n",
    "    print(f\"   Contains {len(pareto_xs)} non-dominated solutions\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid solutions for Pareto front\")\n",
    "\n",
    "print(\"\\nüéâ Optimization completed successfully!\")\n",
    "print(f\"üìà Visualize results with:\")\n",
    "print(f\"   data = np.load('{filename}')\")\n",
    "print(f\"   xs = data['xs']\")\n",
    "print(f\"   ys = data['ys']\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d2a82-7bc4-49da-8c1d-db877aa97f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä ADVANCED ESA SCORE ANALYSIS WITH PROGRESS TRACKING\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from pymoo.indicators.hv import HV\n",
    "import seaborn as sns\n",
    "\n",
    "# Set professional style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ESA Scoring Parameters\n",
    "ESA_REF_POINT = np.array([1.2, 1.4])\n",
    "ESA_MULTIPLIER = 10000.0\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"üìä ADVANCED ESA SCORE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚öôÔ∏è ESA Rules Configuration:\")\n",
    "print(f\"  ‚Ä¢ Reference Point: {ESA_REF_POINT}\")\n",
    "print(f\"  ‚Ä¢ Multiplier: x {ESA_MULTIPLIER:,.0f}\")\n",
    "print(f\"  ‚Ä¢ Requirement: J1 < {ESA_REF_POINT[0]}, J2 < {ESA_REF_POINT[1]}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Initialize HV calculator\n",
    "ind_esa = HV(ref_point=ESA_REF_POINT)\n",
    "\n",
    "def get_esa_score_advanced(F_pop, return_details=False):\n",
    "    \"\"\"\n",
    "    Advanced ESA score calculation with detailed diagnostics.\n",
    "    \"\"\"\n",
    "    if F_pop is None or len(F_pop) == 0:\n",
    "        return (0.0, 0, 0) if return_details else 0.0\n",
    "    \n",
    "    # Filter 1: Remove physically invalid (high penalty)\n",
    "    valid_physics = np.all(F_pop < 100, axis=1)\n",
    "    n_physics_valid = np.sum(valid_physics)\n",
    "    \n",
    "    # Filter 2: ESA bounds (J1 < 1.2 AND J2 < 1.4)\n",
    "    within_bounds = (F_pop[:, 0] < ESA_REF_POINT[0]) & (F_pop[:, 1] < ESA_REF_POINT[1])\n",
    "    n_within_bounds = np.sum(within_bounds)\n",
    "    \n",
    "    # Final mask\n",
    "    final_mask = valid_physics & within_bounds\n",
    "    n_final = np.sum(final_mask)\n",
    "    \n",
    "    if n_final == 0:\n",
    "        if return_details:\n",
    "            return 0.0, n_physics_valid, n_within_bounds\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate HV\n",
    "    hv_raw = ind_esa(F_pop[final_mask])\n",
    "    score = hv_raw * ESA_MULTIPLIER\n",
    "    \n",
    "    if return_details:\n",
    "        return score, n_physics_valid, n_within_bounds\n",
    "    return score\n",
    "\n",
    "# Process MOEA/D history\n",
    "scores = []\n",
    "gens = []\n",
    "valid_counts = []\n",
    "bound_counts = []\n",
    "\n",
    "if 'res' in globals() and hasattr(res, 'history') and len(res.history) > 0:\n",
    "    print(f\"üîÑ Processing {len(res.history)} generations from MOEA/D history...\")\n",
    "    \n",
    "    # Sample for efficiency (every 10 generations)\n",
    "    sample_rate = max(1, len(res.history) // 250)  # Show ~250 points max\n",
    "    \n",
    "    for i, algo in enumerate(res.history[::sample_rate]):\n",
    "        gen = i * sample_rate + 1\n",
    "        F_pop = algo.opt.get(\"F\")\n",
    "        \n",
    "        if F_pop is not None and len(F_pop) > 0:\n",
    "            score, n_valid, n_bounds = get_esa_score_advanced(F_pop, return_details=True)\n",
    "            scores.append(score)\n",
    "            gens.append(gen)\n",
    "            valid_counts.append(n_valid)\n",
    "            bound_counts.append(n_bounds)\n",
    "    \n",
    "    if len(scores) > 0:\n",
    "        final_val = scores[-1]\n",
    "        print(f\"‚úì Processed {len(scores)} sampled generations\")\n",
    "    else:\n",
    "        final_val = 0.0\n",
    "        print(\"‚ö†Ô∏è No valid scores calculated from history\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No MOEA/D history available. Using final population.\")\n",
    "    if 'res' in globals() and res.F is not None:\n",
    "        final_val, n_valid, n_bounds = get_esa_score_advanced(res.F, return_details=True)\n",
    "        scores = [final_val]\n",
    "        gens = [CONFIG['n_gen']]\n",
    "        valid_counts = [n_valid]\n",
    "        bound_counts = [n_bounds]\n",
    "    else:\n",
    "        final_val = 0.0\n",
    "        scores = [0.0]\n",
    "        gens = [1]\n",
    "        valid_counts = [0]\n",
    "        bound_counts = [0]\n",
    "\n",
    "# Create comprehensive figure\n",
    "fig = plt.figure(figsize=(16, 10), dpi=150)\n",
    "\n",
    "# 1. ESA Score Evolution\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.plot(gens, scores, color='#2E86AB', linewidth=2.5, label='ESA Score')\n",
    "ax1.fill_between(gens, scores, color='#2E86AB', alpha=0.2)\n",
    "\n",
    "# Highlight final value\n",
    "if len(scores) > 0:\n",
    "    ax1.scatter(gens[-1], final_val, color='#A23B72', s=150, zorder=5, \n",
    "               edgecolor='black', linewidth=1.5)\n",
    "    ax1.annotate(f'{final_val:,.0f}', \n",
    "                xy=(gens[-1], final_val),\n",
    "                xytext=(gens[-1], final_val * 1.1),\n",
    "                fontsize=11, fontweight='bold', color='#A23B72',\n",
    "                ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.9))\n",
    "\n",
    "ax1.set_title(\"ESA Hypervolume Score Evolution\", fontsize=14, fontweight='bold', pad=15)\n",
    "ax1.set_xlabel(\"Generation\", fontsize=12)\n",
    "ax1.set_ylabel(\"Score (√ó10,000)\", fontsize=12)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "ax1.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# 2. Solution Quality Metrics\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "width = 0.35\n",
    "x = np.arange(len(gens))\n",
    "\n",
    "# Plot stacked bars for last 20 points or all if less\n",
    "n_show = min(20, len(gens))\n",
    "show_idx = slice(-n_show, None) if len(gens) > n_show else slice(None)\n",
    "\n",
    "ax2.bar(x[show_idx], valid_counts[show_idx], width, label='Physically Valid', color='#4CB963')\n",
    "ax2.bar(x[show_idx], bound_counts[show_idx], width, label='Within ESA Bounds', color='#FF9B42',\n",
    "       bottom=valid_counts[show_idx])\n",
    "\n",
    "ax2.set_title(\"Solution Quality Metrics\", fontsize=14, fontweight='bold', pad=15)\n",
    "ax2.set_xlabel(\"Generation (last 20 shown)\", fontsize=12)\n",
    "ax2.set_ylabel(\"Number of Solutions\", fontsize=12)\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 3. Final Population Analysis (if available)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "if 'res' in globals() and res.F is not None:\n",
    "    # Extract real objectives (without penalty)\n",
    "    real_F = []\n",
    "    for i, sol in enumerate(res.X):\n",
    "        x_check = list(sol.copy())\n",
    "        for k in range(10, 20):\n",
    "            x_check[k] = int(round(x_check[k]))\n",
    "        try:\n",
    "            fit = esa_inst.fitness(x_check)\n",
    "            if fit[2] <= 0 and fit[3] <= 0:  # Only valid solutions\n",
    "                real_F.append([fit[0], fit[1]])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(real_F) > 0:\n",
    "        real_F = np.array(real_F)\n",
    "        scatter = ax3.scatter(real_F[:, 0], real_F[:, 1], \n",
    "                             c=0.97*real_F[:, 0] + 0.03*real_F[:, 1],\n",
    "                             cmap='viridis', s=50, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Plot ESA reference box\n",
    "        ax3.axvline(x=1.2, color='red', linestyle='--', alpha=0.7, label='J1 bound')\n",
    "        ax3.axhline(y=1.4, color='red', linestyle='--', alpha=0.7, label='J2 bound')\n",
    "        ax3.fill_betweenx([0, 1.4], 0, 1.2, color='red', alpha=0.1)\n",
    "        \n",
    "        # Plot Pareto front approximation\n",
    "        if len(real_F) > 1:\n",
    "            # Simple Pareto front extraction\n",
    "            pareto_mask = np.ones(len(real_F), dtype=bool)\n",
    "            for i in range(len(real_F)):\n",
    "                for j in range(len(real_F)):\n",
    "                    if i != j and pareto_mask[i]:\n",
    "                        if (real_F[j, 0] <= real_F[i, 0] and \n",
    "                            real_F[j, 1] <= real_F[i, 1] and\n",
    "                            (real_F[j, 0] < real_F[i, 0] or real_F[j, 1] < real_F[i, 1])):\n",
    "                            pareto_mask[i] = False\n",
    "                            break\n",
    "            \n",
    "            pareto_front = real_F[pareto_mask]\n",
    "            pareto_front = pareto_front[np.argsort(pareto_front[:, 0])]\n",
    "            ax3.plot(pareto_front[:, 0], pareto_front[:, 1], \n",
    "                    color='#A23B72', linewidth=2.5, marker='o', \n",
    "                    markersize=8, label='Pareto Front')\n",
    "        \n",
    "        plt.colorbar(scatter, ax=ax3, label='Weighted Score (0.97J1+0.03J2)')\n",
    "        \n",
    "        ax3.set_title(\"Final Population (Valid Solutions)\", fontsize=14, fontweight='bold', pad=15)\n",
    "        ax3.set_xlabel(\"J1 (Communication Latency)\", fontsize=12)\n",
    "        ax3.set_ylabel(\"J2 (Infrastructure Cost)\", fontsize=12)\n",
    "        ax3.legend(loc='upper right')\n",
    "        ax3.grid(True, linestyle='--', alpha=0.7)\n",
    "        ax3.set_xlim([0, max(2.0, np.max(real_F[:, 0]) * 1.1)])\n",
    "        ax3.set_ylim([0, max(2.0, np.max(real_F[:, 1]) * 1.1)])\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No Valid Solutions\\nin Final Population', \n",
    "                ha='center', va='center', transform=ax3.transAxes, fontsize=12)\n",
    "        ax3.set_title(\"Final Population Analysis\", fontsize=14, fontweight='bold', pad=15)\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'No Result Data Available', \n",
    "            ha='center', va='center', transform=ax3.transAxes, fontsize=12)\n",
    "    ax3.set_title(\"Final Population Analysis\", fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "# 4. Performance Summary\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "ax4.axis('off')\n",
    "\n",
    "# Create summary text\n",
    "summary_text = (\n",
    "    f\"OPTIMIZATION SUMMARY\\n\"\n",
    "    f\"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\"\n",
    "    f\"‚Ä¢ Final ESA Score: {final_val:,.0f}\\n\"\n",
    "    f\"‚Ä¢ Total Time: {total_time/3600:.1f} hours\\n\"\n",
    "    f\"‚Ä¢ Generations: {CONFIG['n_gen']:,}\\n\"\n",
    "    f\"‚Ä¢ Population Size: {CONFIG['pop_size']:,}\\n\"\n",
    "    f\"‚Ä¢ CPU Cores Used: {N_CORES}\\n\"\n",
    "    f\"‚Ä¢ Valid Solutions: {valid_solutions_count:,}\\n\"\n",
    "    f\"‚Ä¢ Final J1: {final_stats[0]:.6f}\\n\"\n",
    "    f\"‚Ä¢ Final J2: {final_stats[1]:.6f}\\n\"\n",
    "    f\"‚Ä¢ Feasibility: {'‚úì' if is_valid else '‚úó'}\\n\"\n",
    "    f\"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\"\n",
    "    f\"SURROGATE PERFORMANCE\\n\"\n",
    "    f\"‚Ä¢ Global Candidates: {CONFIG['ml_global_candidates']:,}\\n\"\n",
    "    f\"‚Ä¢ Local Candidates: {CONFIG['ml_local_candidates']:,}\\n\"\n",
    "    f\"‚Ä¢ Speedup Factor: {(CONFIG['ml_global_candidates'] + CONFIG['ml_local_candidates']) * 0.1 / (phase2a_time + phase2b_time):.1f}x\"\n",
    ")\n",
    "\n",
    "ax4.text(0.1, 0.95, summary_text, fontfamily='monospace', fontsize=10,\n",
    "        verticalalignment='top', linespacing=1.5,\n",
    "        bbox=dict(boxstyle=\"round,pad=1\", facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "ax4.set_title(\"Performance Summary\", fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "plt.suptitle(f\"ESA SpOC Challenge Optimization Results - {timestamp}\", \n",
    "            fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "figure_filename = f'esa_analysis_comprehensive_{timestamp}.png'\n",
    "plt.savefig(figure_filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà Analysis completed!\")\n",
    "print(f\"‚úÖ Figure saved as: {figure_filename}\")\n",
    "\n",
    "# Final ESA Score Report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã FINAL ESA SCORE REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Final ESA Score: {final_val:,.4f}\")\n",
    "\n",
    "if final_val == 0:\n",
    "    print(\"\\n‚ùå CRITICAL: Score is ZERO!\")\n",
    "    print(\"   Reasons:\")\n",
    "    print(\"   1. No solutions satisfy J1 < 1.2 AND J2 < 1.4\")\n",
    "    print(\"   2. All solutions violate physical constraints\")\n",
    "    print(\"   3. No valid solutions found in the search\")\n",
    "    print(\"\\n   Recommended actions:\")\n",
    "    print(\"   ‚Ä¢ Increase population size\")\n",
    "    print(\"   ‚Ä¢ Run for more generations\")\n",
    "    print(\"   ‚Ä¢ Adjust penalty weights\")\n",
    "    print(\"   ‚Ä¢ Check constraint handling\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ SUCCESS: Valid ESA score achieved!\")\n",
    "    print(f\"   ‚Ä¢ Score: {final_val:,.0f}\")\n",
    "    print(f\"   ‚Ä¢ Solutions in ESA box: {bound_counts[-1] if len(bound_counts) > 0 else 'N/A'}\")\n",
    "    print(f\"   ‚Ä¢ Physical validity: {valid_counts[-1] if len(valid_counts) > 0 else 'N/A'} solutions\")\n",
    "    \n",
    "    # Quality assessment\n",
    "    if final_val > 10000:\n",
    "        print(\"   üéâ EXCELLENT: High score achieved!\")\n",
    "    elif final_val > 5000:\n",
    "        print(\"   üëç GOOD: Competitive score\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  MODERATE: Room for improvement\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Additional diagnostic if score is low\n",
    "if 0 < final_val < 1000:\n",
    "    print(\"\\nüîç DIAGNOSTIC ANALYSIS:\")\n",
    "    print(\"   Low score indicates:\")\n",
    "    print(\"   1. Few solutions within ESA bounds\")\n",
    "    print(\"   2. Limited hypervolume coverage\")\n",
    "    print(\"   3. Possible constraint violations\")\n",
    "    print(\"\\n   Suggestions:\")\n",
    "    print(\"   1. Focus search near [J1=1.0, J2=1.2] region\")\n",
    "    print(\"   2. Increase local surrogate refinement\")\n",
    "    print(\"   3. Adjust weighted sum coefficients\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ OPTIMIZATION COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
