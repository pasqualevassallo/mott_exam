{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aaf6382-d938-4c2d-af9c-9b28d6928f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:48:32.01 | 1060313 | INFO | time: 6.08 iter: 1 hv: 5489.181468237682\n",
      "18:48:34.03 | 1060313 | INFO | time: 8.1 iter: 2 hv: 5518.253824539779\n",
      "18:48:36.17 | 1060313 | INFO | time: 10.23 iter: 3 hv: 5539.203229958449\n",
      "18:48:37.98 | 1060313 | INFO | time: 12.05 iter: 4 hv: 5556.792681126088\n",
      "18:48:40.04 | 1060313 | INFO | time: 14.11 iter: 5 hv: 5593.137112665992\n",
      "18:48:41.92 | 1060313 | INFO | time: 15.99 iter: 6 hv: 5623.362367203932\n",
      "18:48:43.82 | 1060313 | INFO | time: 17.89 iter: 7 hv: 5667.9999340297145\n",
      "18:48:45.81 | 1060313 | INFO | time: 19.88 iter: 8 hv: 5697.711059186447\n",
      "18:48:48.19 | 1060313 | INFO | time: 22.26 iter: 9 hv: 5705.426058735282\n",
      "18:48:50.12 | 1060313 | INFO | time: 24.19 iter: 10 hv: 5735.640808803019\n",
      "18:48:52.46 | 1060313 | INFO | time: 26.52 iter: 11 hv: 5769.193256084549\n",
      "18:48:53.94 | 1060313 | INFO | time: 28.0 iter: 12 hv: 5778.1899604957935\n",
      "18:48:55.11 | 1060313 | INFO | time: 29.18 iter: 13 hv: 5784.454133117985\n",
      "18:48:57.80 | 1060313 | INFO | time: 31.87 iter: 15 hv: 5821.283909426526\n",
      "18:49:00.26 | 1060313 | INFO | time: 34.33 iter: 17 hv: 5842.564641396232\n",
      "18:49:02.01 | 1060313 | INFO | time: 36.08 iter: 18 hv: 5856.154636485541\n",
      "18:49:02.97 | 1060313 | INFO | time: 37.04 iter: 19 hv: 5889.256508804611\n",
      "18:49:04.88 | 1060313 | INFO | time: 38.95 iter: 21 hv: 5896.371750820439\n",
      "18:49:06.86 | 1060313 | INFO | time: 40.92 iter: 23 hv: 5915.85131167817\n",
      "18:49:09.29 | 1060313 | INFO | time: 43.35 iter: 25 hv: 5915.55705546158\n",
      "18:49:11.70 | 1060313 | INFO | time: 45.77 iter: 27 hv: 5928.492539480884\n",
      "18:49:13.45 | 1060313 | INFO | time: 47.52 iter: 29 hv: 5939.345843084547\n",
      "18:49:14.56 | 1060313 | INFO | time: 48.62 iter: 30 hv: 5960.2867807657085\n",
      "18:49:16.80 | 1060313 | INFO | time: 50.87 iter: 32 hv: 5974.8513478945615\n",
      "18:49:18.78 | 1060313 | INFO | time: 52.85 iter: 34 hv: 5991.684593320468\n",
      "18:49:22.28 | 1060313 | INFO | time: 56.35 iter: 37 hv: 5997.74622981974\n",
      "18:49:23.18 | 1060313 | INFO | time: 57.25 iter: 38 hv: 6009.3401089648005\n",
      "18:49:25.15 | 1060313 | INFO | time: 59.22 iter: 40 hv: 6013.030653074671\n",
      "18:49:25.88 | 1060313 | INFO | time: 59.95 iter: 41 hv: 6013.247219321697\n",
      "18:49:26.76 | 1060313 | INFO | time: 60.83 iter: 42 hv: 6021.382594019445\n",
      "18:49:29.04 | 1060313 | INFO | time: 63.11 iter: 44 hv: 6021.798205368022\n",
      "18:49:31.37 | 1060313 | INFO | time: 65.44 iter: 47 hv: 6039.341731352585\n",
      "18:49:32.38 | 1060313 | INFO | time: 66.45 iter: 48 hv: 6043.324084817944\n",
      "18:49:33.20 | 1060313 | INFO | time: 67.27 iter: 49 hv: 6056.630619790253\n",
      "18:49:35.92 | 1060313 | INFO | time: 69.99 iter: 52 hv: 6057.23079256203\n",
      "18:49:37.11 | 1060313 | INFO | time: 71.18 iter: 53 hv: 6060.413151003338\n",
      "18:49:39.60 | 1060313 | INFO | time: 73.67 iter: 55 hv: 6061.142636414648\n",
      "18:49:40.43 | 1060313 | INFO | time: 74.5 iter: 56 hv: 6072.435980480273\n",
      "18:49:42.28 | 1060313 | INFO | time: 76.34 iter: 58 hv: 6075.216289050287\n",
      "18:49:44.24 | 1060313 | INFO | time: 78.31 iter: 60 hv: 6075.038961959458\n",
      "18:49:46.35 | 1060313 | INFO | time: 80.42 iter: 62 hv: 6082.540755775813\n",
      "18:49:48.68 | 1060313 | INFO | time: 82.75 iter: 64 hv: 6091.967905953846\n",
      "18:49:54.17 | 1060313 | INFO | time: 88.24 iter: 69 hv: 6103.44120933947\n",
      "18:50:00.48 | 1060313 | INFO | time: 94.54 iter: 74 hv: 6106.670380610361\n",
      "18:50:01.43 | 1060313 | INFO | time: 95.49 iter: 75 hv: 6119.620912493985\n",
      "18:50:06.77 | 1060313 | INFO | time: 100.84 iter: 80 hv: 6126.450628352895\n",
      "18:50:08.59 | 1060313 | INFO | time: 102.66 iter: 82 hv: 6126.740655966301\n",
      "18:50:09.47 | 1060313 | INFO | time: 103.54 iter: 83 hv: 6131.385095860643\n",
      "18:50:10.52 | 1060313 | INFO | time: 104.59 iter: 84 hv: 6131.743075068475\n",
      "18:50:11.50 | 1060313 | INFO | time: 105.57 iter: 85 hv: 6138.091978632667\n",
      "18:50:17.33 | 1060313 | INFO | time: 111.4 iter: 91 hv: 6137.908557179031\n",
      "18:50:20.52 | 1060313 | INFO | time: 114.58 iter: 95 hv: 6140.685824039942\n",
      "18:50:21.48 | 1060313 | INFO | time: 115.55 iter: 96 hv: 6147.968146431986\n",
      "18:50:24.30 | 1060313 | INFO | time: 118.37 iter: 99 hv: 6157.702607908302\n",
      "18:50:27.24 | 1060313 | INFO | time: 121.31 iter: 102 hv: 6161.206493878138\n",
      "18:50:37.38 | 1060313 | INFO | time: 131.45 iter: 112 hv: 6166.132784778796\n",
      "18:50:40.78 | 1060313 | INFO | time: 134.85 iter: 115 hv: 6172.30041188544\n",
      "18:50:45.68 | 1060313 | INFO | time: 139.74 iter: 119 hv: 6180.034652382102\n",
      "18:50:48.04 | 1060313 | INFO | time: 142.11 iter: 121 hv: 6181.560115576555\n",
      "18:50:55.55 | 1060313 | INFO | time: 149.62 iter: 128 hv: 6187.68188082987\n",
      "18:50:57.70 | 1060313 | INFO | time: 151.77 iter: 130 hv: 6190.460045103624\n",
      "18:51:11.20 | 1060313 | INFO | time: 165.27 iter: 141 hv: 6196.49480808946\n",
      "18:51:14.31 | 1060313 | INFO | time: 168.38 iter: 143 hv: 6197.743378808183\n",
      "18:51:15.62 | 1060313 | INFO | time: 169.69 iter: 145 hv: 6203.978871797396\n",
      "18:51:23.19 | 1060313 | INFO | time: 177.26 iter: 153 hv: 6211.103649565997\n",
      "18:51:27.55 | 1060313 | INFO | time: 181.62 iter: 157 hv: 6216.3671249716035\n",
      "18:51:32.53 | 1060313 | INFO | time: 186.59 iter: 162 hv: 6222.703654863862\n",
      "18:51:50.74 | 1060313 | INFO | time: 204.81 iter: 177 hv: 6222.462557560943\n",
      "18:51:53.79 | 1060313 | INFO | time: 207.86 iter: 179 hv: 6224.6934700422125\n",
      "18:52:05.75 | 1060313 | INFO | time: 219.81 iter: 189 hv: 6224.594107528282\n",
      "18:52:08.16 | 1060313 | INFO | time: 222.23 iter: 191 hv: 6224.253977940133\n",
      "18:52:21.01 | 1060313 | INFO | time: 235.08 iter: 200 hv: 6237.434387796296\n",
      "18:52:51.63 | 1060313 | INFO | time: 265.7 iter: 221 hv: 6237.671067778972\n",
      "18:52:53.10 | 1060313 | INFO | time: 267.17 iter: 222 hv: 6240.450507917473\n",
      "18:53:07.83 | 1060313 | INFO | time: 281.9 iter: 232 hv: 6241.152193675345\n",
      "18:53:09.29 | 1060313 | INFO | time: 283.36 iter: 233 hv: 6241.571149712741\n",
      "18:53:16.16 | 1060313 | INFO | time: 290.23 iter: 237 hv: 6242.303805779129\n",
      "18:53:18.03 | 1060313 | INFO | time: 292.1 iter: 238 hv: 6242.099441391007\n",
      "18:53:23.25 | 1060313 | INFO | time: 297.32 iter: 241 hv: 6244.724484586053\n",
      "18:53:31.82 | 1060313 | INFO | time: 305.89 iter: 246 hv: 6246.832052756876\n",
      "18:53:47.25 | 1060313 | INFO | time: 321.32 iter: 255 hv: 6249.616164517653\n",
      "18:53:51.74 | 1060313 | INFO | time: 325.81 iter: 258 hv: 6250.083138557244\n",
      "18:53:55.97 | 1060313 | INFO | time: 330.04 iter: 261 hv: 6249.948593527532\n",
      "18:53:57.31 | 1060313 | INFO | time: 331.37 iter: 262 hv: 6251.979879056209\n",
      "18:54:02.39 | 1060313 | INFO | time: 336.46 iter: 266 hv: 6251.82955772767\n",
      "18:54:15.44 | 1060313 | INFO | time: 349.51 iter: 277 hv: 6254.442935952067\n",
      "18:54:16.47 | 1060313 | INFO | time: 350.54 iter: 278 hv: 6257.282956676434\n",
      "18:54:19.44 | 1060313 | INFO | time: 353.51 iter: 281 hv: 6256.8909738785305\n",
      "18:54:26.81 | 1060313 | INFO | time: 360.88 iter: 288 hv: 6256.7334784396835\n",
      "18:54:29.06 | 1060313 | INFO | time: 363.13 iter: 290 hv: 6257.381942639295\n",
      "18:54:31.12 | 1060313 | INFO | time: 365.19 iter: 292 hv: 6256.833642486495\n",
      "18:54:33.31 | 1060313 | INFO | time: 367.38 iter: 294 hv: 6256.946477535672\n",
      "18:54:36.27 | 1060313 | INFO | time: 370.34 iter: 297 hv: 6258.073218388157\n",
      "18:54:37.20 | 1060313 | INFO | time: 371.27 iter: 298 hv: 6260.401489148745\n",
      "18:54:39.93 | 1060313 | INFO | time: 374.0 iter: 301 hv: 6262.591897787837\n",
      "18:54:49.59 | 1060313 | INFO | time: 383.66 iter: 312 hv: 6265.586168890174\n",
      "18:54:54.76 | 1060313 | INFO | time: 388.82 iter: 318 hv: 6265.62912966512\n",
      "18:55:03.63 | 1060313 | INFO | time: 397.7 iter: 329 hv: 6267.8403159519\n",
      "18:55:06.74 | 1060313 | INFO | time: 400.81 iter: 333 hv: 6269.269155709477\n",
      "18:55:10.85 | 1060313 | INFO | time: 404.91 iter: 338 hv: 6269.054991685325\n",
      "18:55:14.01 | 1060313 | INFO | time: 408.08 iter: 342 hv: 6268.988899510329\n",
      "18:55:14.87 | 1060313 | INFO | time: 408.94 iter: 343 hv: 6270.337521662719\n",
      "18:55:21.33 | 1060313 | INFO | time: 415.39 iter: 351 hv: 6271.538717993582\n",
      "18:55:37.06 | 1060313 | INFO | time: 431.13 iter: 370 hv: 6272.156435582466\n",
      "18:55:38.71 | 1060313 | INFO | time: 432.78 iter: 372 hv: 6272.296938763555\n",
      "18:55:39.53 | 1060313 | INFO | time: 433.6 iter: 373 hv: 6273.985527254411\n",
      "18:55:40.36 | 1060313 | INFO | time: 434.43 iter: 374 hv: 6274.468533623355\n",
      "18:55:46.18 | 1060313 | INFO | time: 440.25 iter: 381 hv: 6275.4316417630125\n",
      "18:55:47.04 | 1060313 | INFO | time: 441.1 iter: 382 hv: 6276.7801144283185\n",
      "18:55:54.33 | 1060313 | INFO | time: 448.4 iter: 391 hv: 6281.671364826841\n",
      "18:56:16.25 | 1060313 | INFO | time: 470.32 iter: 423 hv: 6281.674278252296\n",
      "18:56:42.75 | 1060313 | INFO | time: 496.82 iter: 464 hv: 6281.365395055597\n",
      "18:56:48.60 | 1060313 | INFO | time: 502.67 iter: 473 hv: 6282.518905148031\n",
      "18:56:49.95 | 1060313 | INFO | time: 504.02 iter: 475 hv: 6284.46927878403\n",
      "18:57:16.55 | 1060313 | INFO | time: 530.62 iter: 517 hv: 6284.768602069035\n",
      "18:57:20.01 | 1060313 | INFO | time: 534.08 iter: 523 hv: 6285.164790583138\n",
      "18:57:20.70 | 1060313 | INFO | time: 534.77 iter: 524 hv: 6285.577804071185\n",
      "18:57:32.99 | 1060313 | INFO | time: 547.06 iter: 544 hv: 6287.882789630155\n",
      "18:57:36.70 | 1060313 | INFO | time: 550.77 iter: 550 hv: 6287.652899378576\n",
      "18:58:11.10 | 1060313 | INFO | time: 585.17 iter: 607 hv: 6290.730224795425\n",
      "18:58:31.40 | 1060313 | INFO | time: 605.47 iter: 640 hv: 6293.583490634459\n",
      "18:58:35.06 | 1060313 | INFO | time: 609.12 iter: 646 hv: 6294.2120372696745\n",
      "18:59:15.47 | 1060313 | INFO | time: 649.54 iter: 711 hv: 6293.703678767495\n",
      "18:59:38.24 | 1060313 | INFO | time: 672.31 iter: 750 hv: 6295.251953773976\n",
      "18:59:42.73 | 1060313 | INFO | time: 676.8 iter: 757 hv: 6295.433936759918\n",
      "19:00:16.45 | 1060313 | INFO | time: 710.52 iter: 813 hv: 6296.393622978026\n",
      "19:00:39.54 | 1060313 | INFO | time: 733.6 iter: 855 hv: 6298.538506559307\n",
      "19:00:46.83 | 1060313 | INFO | time: 740.89 iter: 868 hv: 6299.713229536089\n",
      "19:00:53.49 | 1060313 | INFO | time: 747.56 iter: 880 hv: 6299.188334477689\n",
      "19:01:47.91 | 1060313 | INFO | time: 801.98 iter: 973 hv: 6299.210902321908\n",
      "19:02:10.88 | 1060313 | INFO | time: 824.95 iter: 1011 hv: 6300.062093226326\n",
      "19:02:41.23 | 1060313 | INFO | time: 855.3 iter: 1065 hv: 6303.946282546311\n",
      "19:02:42.88 | 1060313 | INFO | time: 856.95 iter: 1068 hv: 6304.846552135031\n",
      "19:02:57.45 | 1060313 | INFO | time: 871.51 iter: 1094 hv: 6304.804510657229\n",
      "19:03:00.46 | 1060313 | INFO | time: 874.53 iter: 1099 hv: 6305.398968032891\n",
      "19:04:02.76 | 1060313 | INFO | time: 936.83 iter: 1201 hv: 6306.614719842389\n",
      "19:05:33.79 | 1060313 | INFO | time: 1027.86 iter: 1368 hv: 6306.082743273508\n",
      "19:05:42.35 | 1060313 | INFO | time: 1036.42 iter: 1383 hv: 6307.426396661801\n",
      "19:05:47.09 | 1060313 | INFO | time: 1041.15 iter: 1391 hv: 6308.218590495729\n",
      "19:06:03.46 | 1060313 | INFO | time: 1057.53 iter: 1419 hv: 6311.669859173438\n",
      "19:06:05.19 | 1060313 | INFO | time: 1059.26 iter: 1422 hv: 6311.761182190412\n",
      "19:06:23.58 | 1060313 | INFO | time: 1077.64 iter: 1455 hv: 6311.187408343773\n",
      "19:06:25.34 | 1060313 | INFO | time: 1079.4 iter: 1458 hv: 6314.751858930608\n",
      "19:06:30.58 | 1060313 | INFO | time: 1084.65 iter: 1468 hv: 6315.568066602009\n",
      "19:07:12.56 | 1060313 | INFO | time: 1126.63 iter: 1550 hv: 6318.022686005536\n",
      "19:07:18.84 | 1060313 | INFO | time: 1132.91 iter: 1564 hv: 6318.10631361069\n",
      "19:07:53.42 | 1060313 | INFO | time: 1167.49 iter: 1634 hv: 6320.321449958417\n",
      "19:08:00.85 | 1060313 | INFO | time: 1174.92 iter: 1650 hv: 6323.688792360727\n",
      "19:10:06.90 | 1060313 | INFO | time: 1300.96 iter: 1909 hv: 6323.343371546175\n",
      "19:10:17.03 | 1060313 | INFO | time: 1311.1 iter: 1929 hv: 6323.223957697464\n",
      "19:11:05.89 | 1060313 | INFO | time: 1359.95 iter: 2032 hv: 6323.634093441061\n",
      "19:11:07.32 | 1060313 | INFO | time: 1361.39 iter: 2035 hv: 6323.362330045865\n",
      "19:11:20.46 | 1060313 | INFO | time: 1374.53 iter: 2063 hv: 6325.899941552573\n",
      "19:12:48.89 | 1060313 | INFO | time: 1462.95 iter: 2245 hv: 6325.551918755284\n"
     ]
    }
   ],
   "source": [
    "# See original code at\n",
    "# https://optimize.esa.int/challenge/spoc-2-quantum-communications-constellations/About\n",
    "# https://optimize.esa.int/challenge/spoc-2-quantum-communications-constellations/p/quantum-communications-constellations\n",
    "# \n",
    "# Changes: \n",
    "# - Factor 30 speedup using numba and igraph\n",
    "# - Added competitive algorithms\n",
    "# - See corresponding tutorial \n",
    "#   https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/ESAChallenge.adoc\n",
    "\n",
    "# Requires pykep which needs python 3.8, \n",
    "# Create an python 3.8 environment:\n",
    "\n",
    "# mamba create -n env38 python=3.8\n",
    "# conda activate env38\n",
    "\n",
    "# Install dependencies:\n",
    "\n",
    "# mamba install pykep\n",
    "# mamba install pygmo\n",
    "# pip install networkx\n",
    "# pip install sgp4\n",
    "# pip install seaborn\n",
    "# pip install matplotlib\n",
    "# pip install igraph\n",
    "# pip install pymoo\n",
    "\n",
    "# Tested using https://docs.conda.io/en/main/miniconda.html on Linux Mint 21.2\n",
    "\n",
    "# Basic imports\n",
    "import pykep as pk\n",
    "import pygmo as pg\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os, time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys \n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, format=\"{time:HH:mm:ss.SS} | {process} | {level} | {message}\", level=\"INFO\")\n",
    "logger.add(\"log_{time}.txt\", format=\"{time:HH:mm:ss.SS} | {process} | {level} | {message}\", level=\"INFO\")\n",
    "\n",
    "import seaborn as sns\n",
    "# SGP4 - we use SPG4 to propagate orbits around New Mars as a proxy\n",
    "# for a plausible orbital positions propagator around a habitable planet\n",
    "from sgp4.api import Satrec, SatrecArray\n",
    "from sgp4.api import WGS72\n",
    "\n",
    "# Networkx\n",
    "import igraph as ig # for speed\n",
    "import networkx as nx\n",
    "\n",
    "# Static data\n",
    "def get_mothership_satellites():\n",
    "    \"\"\"Construct array of mothership orbital elements\n",
    "    (the TLEs of actual Earth-orbiting satellites below are used as a proxy for\n",
    "    plausible orbital dynamics around a habitable planet)\n",
    "    \"\"\"\n",
    "    mothership_tles = [\n",
    "        [\n",
    "            \"1 39634U 14016A   22349.82483685  .00000056  00000-0  21508-4 0  9992\",\n",
    "            \"2 39634  98.1813 354.7934 0001199  83.3324 276.7993 14.59201191463475\"\n",
    "        ],\n",
    "        [\n",
    "            \"1 26400U 00037A   00208.84261022 +.00077745 +00000-0 +00000-0 0  9995\",\n",
    "            \"2 26400 051.5790 297.6001 0012791 171.3037 188.7763 15.69818870002328\"\n",
    "        ],\n",
    "        [\n",
    "            \"1 36508U 10013A   22349.92638064  .00000262  00000-0  64328-4 0  9992\",\n",
    "            \"2 36508  92.0240 328.0627 0004726  21.3451 338.7953 14.51905975672463\"\n",
    "        ],\n",
    "        [\n",
    "            \"1 40128U 14050A   22349.31276420 -.00000077  00000-0  00000-0 0  9995\",\n",
    "            \"2 40128  50.1564 325.0733 1614819 130.5958 244.6527  1.85519534 54574\"\n",
    "        ],\n",
    "        [\n",
    "            \"1 49810U 21116B   23065.71091236 -.00000083  00000+0  00000+0 0  9998\",\n",
    "            \"2 49810  57.2480  13.9949 0001242 301.4399 239.8890  1.70475839  7777\"\n",
    "        ],\n",
    "        [\n",
    "            \"1 44878U 19092F   22349.75758852  .00015493  00000-0  00000-0 0  9998\",\n",
    "            \"2 44878  97.4767 172.6133 0012815  68.6990 291.5614 15.23910904165768\"\n",
    "        ],\n",
    "        [\n",
    "            \"1 04382U 70034A   22349.88472104  .00001138  00000-0  18306-3 0  9999\",\n",
    "            \"2 04382  68.4200 140.9159 1043234  48.2283 320.3286 13.08911192477908\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Assembling the list of Satrec motherships\n",
    "    motherships = []\n",
    "    for tle in mothership_tles:\n",
    "        motherships.append(Satrec.twoline2rv(tle[0], tle[1]))\n",
    "    return motherships\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def line_of_sight(r1,r2):\n",
    "    \"\"\"Given two position vectors returns the distance of the line of sight to the origin\n",
    "\n",
    "    Args:\n",
    "        r1 (numpy array): first point\n",
    "        r2 (numpy array): second point\n",
    "    \"\"\"\n",
    "    denom = np.linalg.norm(r2-r1)\n",
    "    if denom < 1e-6:\n",
    "        # if r1 ~= r2, it will return the norm of r1\n",
    "        return np.linalg.norm(r1)\n",
    "    else:\n",
    "        r21 = (r2-r1) / denom\n",
    "        h1 = np.dot(r1,r21)\n",
    "        arg = np.linalg.norm(r1)**2 - h1**2\n",
    "        # We check for a positive arg in case r1 and r2 are near collinearity\n",
    "        return np.sqrt(arg) if arg > 1e-6 else 0.0\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def zenith_angle(src, dst):\n",
    "    \"\"\"Computes the cosine of the zenith angle (theta_z) of the LOS between source and destination node\n",
    "    \n",
    "    Args:\n",
    "        src (numpy array, N_r x 3): rover x, y, z positions\n",
    "        dst (numpy array, N_s x 3): mothership x, y, z positions\n",
    "    \n",
    "    Returns:\n",
    "        float: cosine of the zenith angle\n",
    "    \"\"\"\n",
    "    dpos = dst - src\n",
    "    if np.linalg.norm(dpos) < 1e-6:\n",
    "        cos_theta_z = 0\n",
    "    else:\n",
    "        cos_theta_z = np.dot(dpos, src) / (np.linalg.norm(dpos) * np.linalg.norm(src))\n",
    "    return cos_theta_z\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def qkd_metric(idx, src, dst, cos_theta_z, eta, eps_z, n_rovers):\n",
    "    \"\"\"Computes the edge weight according to QKD probabilities\n",
    "    \n",
    "        Args:\n",
    "            idx (int): index of node in the graph\n",
    "            src (numpy array, 1x3): position of source node\n",
    "            dst (numpy array, 1x3): position of destination node\n",
    "            cos_theta_z (float): cosine of the zenith angle of qkd link\n",
    "            eta (int): satellite quality indicator for corresponding constellation\n",
    "    \n",
    "        Returns:\n",
    "            float: edge weight\n",
    "            float: communications link distance between src and dst\n",
    "    \"\"\"\n",
    "    edge_weight = -np.log(eta) # constellation quality score\n",
    "    d_link = np.linalg.norm(src - dst) # distance of communications link\n",
    "    edge_weight += 2 * np.log(d_link) # final edge weight\n",
    "    if edge_weight < 0:\n",
    "        # Safeguard: whenever this happens, the collision-avoidance constraint is\n",
    "        # also not satisfied. Nevertheless, we must return a value for the edge weight\n",
    "        # to ensure that the fitness does not throw (a negative valued edge would also\n",
    "        # imply the non-existence of a shortest path)\n",
    "        edge_weight = 1e3\n",
    "    \n",
    "    if idx <= n_rovers:\n",
    "        if cos_theta_z >= eps_z: # Apply max zenith angle constraint to mothership-rover link\n",
    "            edge_weight += 1.0 / np.sin(np.pi / 2 - np.arccos(cos_theta_z))\n",
    "        else:\n",
    "            edge_weight = 0\n",
    "    return edge_weight, d_link\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def get_adjmatrix(pos, ep_idx, eta, num_w1_sats, LOS, N, eps_z, n_rovers):\n",
    "    adjmatrix = np.zeros((N, N))\n",
    "    d_min = np.inf\n",
    "    for i in range(N):\n",
    "        for j in range(i):\n",
    "            # Ensure there is LOS\n",
    "            los = line_of_sight(pos[i, ep_idx, :], pos[j, ep_idx, :])\n",
    "            cos_theta_z = zenith_angle(pos[i, ep_idx, :], pos[j, ep_idx, :])\n",
    "            if los >= LOS or cos_theta_z > 0:\n",
    "                # Eta based on j because it is the destination satellite in the link\n",
    "                eta_j = eta[0] if j < num_w1_sats else eta[1]\n",
    "                adjmatrix[i,j], d_link = \\\n",
    "                    qkd_metric(N-i, pos[i, ep_idx, :], pos[j, ep_idx, :], cos_theta_z, eta_j, eps_z, n_rovers)\n",
    "                if d_link < d_min:\n",
    "                    d_min = d_link\n",
    "                adjmatrix[j,i] = adjmatrix[i,j]\n",
    "    return adjmatrix, d_min\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def construct_rover_pos(lambda0, phi0, n_rovers, jds, R_p, w_p):\n",
    "    \"\"\"Computes the position of the rovers at time t based on the initial latitude and longitude\n",
    "    \n",
    "    Args:\n",
    "        lambda0 (float, N_r x 1): initial latitudes of the rovers\n",
    "        phi0 (float, N_r x 1): initial longitudes of the rovers\n",
    "\n",
    "    Returns:\n",
    "        float, n_rovers x n_epochs x 3: rover x, y, z positions\n",
    "    \"\"\"\n",
    "    pos_r = np.zeros((n_rovers, jds.shape[0], 3))\n",
    "    time_range = (jds - jds[0]) * 24 * 3600 # in seconds\n",
    "    for i, t in enumerate(time_range):\n",
    "        pos_r[:, i, 0] = R_p * np.cos(lambda0) * np.cos(phi0 + w_p * t) # x\n",
    "        pos_r[:, i, 1] = R_p * np.cos(lambda0) * np.sin(phi0 + w_p * t) # y\n",
    "        pos_r[:, i, 2] = R_p * np.sin(lambda0) # z\n",
    "    return pos_r\n",
    "\n",
    "class constellation_udp:\n",
    "    \"\"\"A Pygmo compatible UDP (User Defined Problem) representing the constellation design problem for SpOC 2023.\n",
    "\n",
    "    Two Walker constellations are defined in a mixint chromosome:\n",
    "        x = [a1,ei,i1,w1,eta1] + [a2,e2,i2,w2,eta2] + [S1,P1,F1] + [S2,P2,F2] + [r1,r2,r3,r4]\n",
    "\n",
    "    The constellations must relay information between 7 motherships in orbit and 4 rovers on the surface of New Mars\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "\n",
    "        # Define the time grid over which to optimize the communications network\n",
    "        self._t0 = 10000 # starting epoch in mjd2000\n",
    "        self.n_epochs = 11 # number of epochs in time grid to consider\n",
    "        self._duration = 10 # difference between the first and last epoch considered in years\n",
    "        jd0, fr = pk.epoch(self._t0, 'mjd2000').jd, 0.0 # reference Julian date\n",
    "        self.jds = np.linspace(jd0, jd0 + self._duration * 365.25, self.n_epochs) # time grid in JD\n",
    "        self.frs = self.jds * fr # date fractions (defaults to 0)\n",
    "\n",
    "        # Reference epoch for SGP4 is 1949 December 31 00:00 UT\n",
    "        self.ep_ref = pk.epoch_from_iso_string(\"19491231T000000\")\n",
    "\n",
    "        # SGP4-ready mothership satellites\n",
    "        mothership_satellites = get_mothership_satellites()\n",
    "        self.pos_m = self.construct_mothership_pos(SatrecArray(mothership_satellites))\n",
    "        self.n_motherships = len(mothership_satellites)\n",
    "\n",
    "        # Latitudes and longitudes of rovers\n",
    "        rovers_db_path = os.path.join(\".\", \"data\", \"spoc2\", \"constellations\", \"rovers.txt\")\n",
    "        self.rovers_db = np.loadtxt(rovers_db_path)\n",
    "        self.lambdas = self.rovers_db[:, 0] # latitudes\n",
    "        self.phis = self.rovers_db[:, 1] # longitudes\n",
    "        self._min_rover_dist = 3000 # minimum inter-rover distance (km)\n",
    "        self.n_rovers = 4\n",
    "\n",
    "        # Minimum line-of-sight parameter (km)\n",
    "        # Radius amplification factor: 1.05\n",
    "        self.LOS = 1.05 * pk.EARTH_RADIUS / 1000.0\n",
    "        # Radius of the New-Mars planet (km)\n",
    "        self.R_p = pk.EARTH_RADIUS / 1000.0\n",
    "        # Angular velocity of New Mars (rad/s)\n",
    "        self.w_p = 7.29e-5 # 2 * pi / (23 hours 56 minutes 4 seconds)\n",
    "        # Threshold zenith angle constraint for rover-sat link (rad)\n",
    "        self._zenith_angle = np.pi / 3\n",
    "        self.eps_z = np.cos(self._zenith_angle)\n",
    "        # Minimum inter-satellite distance (km)\n",
    "        self._min_sat_dist = 50\n",
    "\n",
    "    def get_bounds(self):\n",
    "        \"\"\"Get bounds for the decision variables.\n",
    "\n",
    "        Returns:\n",
    "            Tuple of lists: bounds for the decision variables.\n",
    "        \"\"\"\n",
    "        lb = [1.06, 0., 0., 0., 1.0] + [2.0, 0., 0., 0., 1.0] + [4, 2, 0] + [4, 2, 0] + [0, 0, 0, 0]\n",
    "        #ub = [1.8, 0.02, np.pi, 2*np.pi, 1000.0] + [3.5, 0.1, np.pi, 2*np.pi, 1000.0] + [10, 10, 9] + [10, 10, 9] + [99, 99, 99, 99]\n",
    "        # we adapt the boundaries so that they work with a continuous optimizer\n",
    "        ub = [1.8, 0.02, np.pi, 2*np.pi, 1000.0] + [3.5, 0.1, np.pi, 2*np.pi, 1000.0] + \\\n",
    "                [10.9999, 10.9999, 9.9999] + [10.9999, 10.9999, 9.9999] + [99.9999, 99.9999, 99.9999, 99.9999]\n",
    "        return (lb, ub)\n",
    "    \n",
    "    def get_ints(self):\n",
    "        return np.array([False]*10 + [True]*10)\n",
    "\n",
    "    def get_nix(self):\n",
    "        \"\"\"Get number of integer variables.\n",
    "\n",
    "        Returns:\n",
    "            int: number of integer variables.\n",
    "        \"\"\"\n",
    "        return 6 + 4\n",
    "\n",
    "    def get_nobj(self):\n",
    "        \"\"\"Get number of objectives.\n",
    "\n",
    "        Returns:\n",
    "            int: the number of objectives\n",
    "        \"\"\"\n",
    "        return 2\n",
    "    \n",
    "    def get_nic(self):\n",
    "        \"\"\"Get number of inequality constraints.\n",
    "\n",
    "        Returns:\n",
    "            int: the number of constraints\n",
    "        \"\"\"\n",
    "        return 2\n",
    "    \n",
    "    def get_rover_constraint(self, lambda0, phi0):\n",
    "        \"\"\"Evaluate the rover constraint (minimum distance between any two rovers)\n",
    "\n",
    "        Args:\n",
    "            lambda0 (float, N_r x 1): latitudes of the rovers\n",
    "            phi0 (float, N_r x 1): longitudes of the rovers\n",
    "\n",
    "        Returns\n",
    "            float: the difference between the actual and allowable minimum distance between rovers\n",
    "        \"\"\"\n",
    "        # Compute rover positions on the planet\n",
    "        pos = np.zeros((self.n_rovers, 3))\n",
    "        pos[:, 0] = np.sin(lambda0) * np.cos(phi0)\n",
    "        pos[:, 1] = np.cos(lambda0) * np.cos(phi0)\n",
    "        pos[:, 2] = np.sin(phi0)\n",
    "        def safe_arccos(u, v):\n",
    "            inner_product = np.dot(u, v)\n",
    "            if inner_product > 1:\n",
    "                return 0\n",
    "            if inner_product < -1:\n",
    "                return np.pi\n",
    "            return np.arccos(inner_product)\n",
    "        d = scipy.spatial.distance.cdist(pos, pos, lambda u, v: pk.EARTH_RADIUS/1000 * safe_arccos(u, v))\n",
    "        d = d + np.diag([np.inf]*4)\n",
    "        min_d = np.min(d)\n",
    "        # Will be negative if min(d) is larger than the min allowable inter-rover distance\n",
    "        return self._min_rover_dist - min_d, min_d\n",
    "    \n",
    "    def get_sat_constraint(self, d_min):\n",
    "        \"\"\"Evaluate the satellite constraint (minimum distance between any two satellites)\n",
    "\n",
    "        Args:\n",
    "            d_min (float): the minimum distance between any two satellites at any epoch\n",
    "\n",
    "        Returns:\n",
    "            float: the difference between the actual and allowable minimum distance between satellites\n",
    "        \"\"\"\n",
    "        # Will be negative if d_min is larger than the min allowable inter-satellite distance\n",
    "        return self._min_sat_dist - d_min\n",
    "\n",
    "\n",
    "    def generate_walker(self, S,P,F,a,e,incl,w,t0):\n",
    "        \"\"\"Generates a Walker constallation as a SatrecArray\n",
    "\n",
    "        Args:\n",
    "            S (int): number of satellites per plane\n",
    "            P (int): number of planes        \n",
    "            F (int): spacing parameter (i.e. if 2 phasing repeats each 2 planes)\n",
    "            a (float): semi-major axis\n",
    "            e (float): eccentricity\n",
    "            incl (float): inclination\n",
    "            w (float): argument of perigee\n",
    "            t0 (float): epoch\n",
    "\n",
    "        Returns:\n",
    "            SatrecArray: satellites ready to be SGP4 propagated\n",
    "        \"\"\"\n",
    "        walker_l = []\n",
    "        mean_motion = np.sqrt(pk.MU_EARTH/a**3/pk.EARTH_RADIUS**3)\n",
    "        # planes\n",
    "        for i in range(P):\n",
    "            #satellites\n",
    "            for j in range(S):\n",
    "                satellite = Satrec()\n",
    "                satellite.sgp4init(\n",
    "                    WGS72,                            # gravity model\n",
    "                    'i',                              # 'a' = old AFSPC mode, 'i' = improved mode\n",
    "                    j + i*S,                          # satnum: Satellite number\n",
    "                    t0-self.ep_ref.mjd2000,           # epoch: days since 1949 December 31 00:00 UT\n",
    "                    0.0,                              # bstar: drag coefficient (1/earth radii) - 3.8792e-05\n",
    "                    0.0,                              # ndot: ballistic coefficient (revs/day)\n",
    "                    0.0,                               # nddot: mean motion 2nd derivative (revs/day^3)\n",
    "                    e,                                # ecco: eccentricity\n",
    "                    w,                                # argpo: argument of perigee (radians)\n",
    "                    incl,                             # inclo: inclination (radians)\n",
    "                    2*np.pi/P/S*F*i+2.*np.pi/S*j,     # mo: mean anomaly (radians)\n",
    "                    mean_motion*60,                   # no_kozai: mean motion (radians/minute)\n",
    "                    2.*np.pi/P*i                      # nodeo: R.A. of ascending node (radians)\n",
    "                )\n",
    "                walker_l.append(satellite)\n",
    "        # Creating the vectorized list\n",
    "        return SatrecArray(walker_l)\n",
    "    \n",
    "    def build_graph(self, ep_idx, pos, num_w1_sats, eta):\n",
    "        \"\"\"Builds a networkx graph from the satellite positions. Links are weighted via a \"QKD-inspired metric\n",
    "        and only exist when motherships/constellation satellites/rovers have line-of-sight\n",
    "\n",
    "        Args:\n",
    "            ep_idx (int): idx of the epoch in the time grid \n",
    "            pos (numpy array 3xN): position vector of the satellites\n",
    "            num_w1_sats (int): number of satellites in the first Walker constellation\n",
    "            eta (tuple): satellite quality indicator for each Walker constellation\n",
    "\n",
    "        Returns:\n",
    "            igraph graph: nodes are motherships/Walker satellites/rovers; links are distances when there is LOS\n",
    "        \"\"\"\n",
    "        N = pos[:, ep_idx, :].shape[0] # number of vertices\n",
    "        adjmatrix, d_min = get_adjmatrix(pos, ep_idx, eta, num_w1_sats, self.LOS, N, self.eps_z, self.n_rovers)\n",
    "        g = ig.Graph.Adjacency((adjmatrix > 0).tolist())\n",
    "        g.es['weight'] = adjmatrix[adjmatrix.nonzero()]\n",
    "        return g, adjmatrix, d_min\n",
    "\n",
    "    def average_shortest_path(self, G, src, dst):\n",
    "        \"\"\"Computes the average shortest path length between the source and destination *partitions* of nodes in the graph *G*\n",
    "        (the source is assumed to be the motherships and the destination the rovers)\n",
    "\n",
    "        Args:\n",
    "            G (networkx graph): The graph\n",
    "            src (int): the number of motherships (to be used as a negative index in G)\n",
    "            dst (int): the number of rovers (to be used as a negative index in G)\n",
    "\n",
    "        Returns:\n",
    "            float: average shortest path\n",
    "        \"\"\"\n",
    "        n_nodes = G.vcount()\n",
    "        src0 = n_nodes - src - dst\n",
    "        dst0 = n_nodes - dst\n",
    "        sp = np.array(G.distances(list(range(src0, src0+src)), \\\n",
    "                                  list(range(dst0, dst0+dst)), weights=G.es[\"weight\"]))\n",
    "        return np.mean(sp)\n",
    "\n",
    "    def construct_walkers(self, x):\n",
    "        \"\"\"Generates two Walker constellations according to specifications\n",
    "        \n",
    "        Args:\n",
    "            x (list): chromosome describing the New Mars communications infrastructure\n",
    "\n",
    "        Returns:\n",
    "            SatrecArray: Walker1 constellation satellites ready to be SGP4 propagated\n",
    "            SatrecArray: Walker2 constellation satellites ready to be SGP4 propagated\n",
    "        \"\"\"\n",
    "        # Parse the chromosome\n",
    "        a1,e1,i1,w1,_,a2,e2,i2,w2,_,S1,P1,F1,S2,P2,F2,_,_,_,_ = x\n",
    "        # Construct the 1st walker constellation as a SatrecArray\n",
    "        walker1 = self.generate_walker(int(S1),int(P1),int(F1),a1,e1,i1,w1,self._t0)\n",
    "        # Construct the 2nd walker constellation as a SatrecArray\n",
    "        walker2 = self.generate_walker(int(S2),int(P2),int(F2),a2,e2,i2,w2,self._t0)\n",
    "        return walker1, walker2\n",
    "\n",
    "    def construct_mothership_pos(self, motherships):\n",
    "        \"\"\"Computes the position of the motherships over a predefined time grid\n",
    "        \n",
    "        Args:\n",
    "            motherships (SatrecArray): mothership satellites ready to be SGP4 propagated\n",
    "\n",
    "        Returns:\n",
    "            float, n_motherships x n_epochs x 3: mothership x, y, z positions\n",
    "        \"\"\"\n",
    "\n",
    "        err, pos, _ = motherships.sgp4(self.jds, self.frs)\n",
    "        # Check propagation went well\n",
    "        if not np.all(err == 0):\n",
    "            raise ValueError(\"The motherships cannot be propagated succesfully on the defined time grid\")\n",
    "        return pos\n",
    "\n",
    "    def construct_pos(self, walker1, walker2, pos_r):\n",
    "        \"\"\"Construct cumulative position of Walker satellites, motherships and rovers\n",
    "\n",
    "        Args:\n",
    "            walker1 (SatrecArray): Walker1 constellation satellites ready to be SGP4 propagated\n",
    "            walker2 (SatrecArray): Walker2 constellation satellites ready to be SGP4 propagated\n",
    "            pos_r (float, n_rovers x n_epochs x 3): rover x, y, z positions\n",
    "\n",
    "        Returns:\n",
    "            float, (S1xP1 + S2xP2 + n_motherships + n_rovers) x n_epochs x 3: overall position vector\n",
    "        \"\"\"\n",
    "        # Compute ephemerides for Walker1 satellites at all epochs)\n",
    "        err_w1, pos_w1, _ = walker1.sgp4(self.jds, self.frs)\n",
    "        # Compute ephemerides for Walker2 satellites at all epochs)\n",
    "        err_w2, pos_w2, _ = walker2.sgp4(self.jds, self.frs)\n",
    "        # Check propagation went well\n",
    "        if not (np.all(err_w1 == 0) and np.all(err_w2 == 0)):\n",
    "            raise ValueError(\"The walker constellations cannot be propagated successfully on the defined time grid\")\n",
    "        # Position vector for Walker constellation satellites, motherships and rovers)\n",
    "        cum_pos = np.concatenate((pos_w1,pos_w2, self.pos_m, pos_r))\n",
    "        return cum_pos\n",
    "\n",
    "    def fitness(self, x, verbose=False):\n",
    "        \"\"\"Evaluate the fitness of the decision variables.\n",
    "\n",
    "        Args:\n",
    "            x (list): chromosome describing the New Mars communications infrastructure\n",
    "            verbose (bool): If True, print some info.\n",
    "\n",
    "        Returns:\n",
    "            float: fitness for average shortest path\n",
    "            float: fitness for total number of satellites\n",
    "            float: constraint for rover positioning\n",
    "        \"\"\"\n",
    "        # Construct the Walker constellations based on input chromosome \n",
    "        walker1, walker2 = self.construct_walkers(x)\n",
    "        # Extract the quality factors and the number of satellites in the Walkers\n",
    "        _,_,_,_,eta1,_,_,_,_,eta2,S1,P1,_,S2,P2,_,_,_,_,_ = x\n",
    "        N1 = S1 * P1\n",
    "        N2 = S2 * P2\n",
    "        # Extract the rover indices from the input chromosome\n",
    "        rovers_idx = np.array(x[-4:]).astype(int)\n",
    "        # Look up latitude and longitudes corresponding to rover indices\n",
    "        lambda0 = self.lambdas[rovers_idx]\n",
    "        phi0 = self.phis[rovers_idx]\n",
    "        # Construct the rover positions\n",
    "        rovers = construct_rover_pos(lambda0, phi0, self.n_rovers, self.jds, self.R_p, self.w_p)\n",
    "        # Concatenate the position of the Walkers, motherships and rover\n",
    "        cum_pos = self.construct_pos(walker1, walker2, rovers)\n",
    "\n",
    "        # Evaluating the fitness function\n",
    "        if verbose:\n",
    "            print(\"FITNESS EVALUATION:\")\n",
    "\n",
    "        # First objective (minimize):\n",
    "        # Compute the average shortest path between any mothership-rover pair\n",
    "        # Iterate over epochs\n",
    "        f1 = 0\n",
    "        nf1 = 34 # f1 normalization factor\n",
    "        d_sat_min_ep = np.inf\n",
    "        for ep_idx in range(1, self.n_epochs):\n",
    "            # Constructs the graph:\n",
    "            # Nodes: Walker sats + motherships + rovers\n",
    "            # Edges: LOS communication\n",
    "            G, _, d_sat_min = self.build_graph(ep_idx, cum_pos, N1, (eta1, eta2))\n",
    "            if d_sat_min < d_sat_min_ep:\n",
    "                d_sat_min_ep = d_sat_min\n",
    "            f1 += self.average_shortest_path(G, self.n_motherships, self.n_rovers)\n",
    "\n",
    "        # Average over the number of epochs\n",
    "        f1 /= (self.n_epochs - 1)\n",
    "\n",
    "        # Second objective (minimize):\n",
    "        # Compute the total number of satellites (weighted by the quality factors)\n",
    "        f2 = eta1 * N1 + eta2 * N2\n",
    "        nf2 = 100000 # f2 normalization factor\n",
    "\n",
    "        # Constraints:\n",
    "        # The minimum distance between any two rovers needs to be at least 3000km\n",
    "        # to ensure good coverage of the surface of New Mars\n",
    "        min_rover_d, d_rover_min = self.get_rover_constraint(lambda0, phi0)\n",
    "        # The minimum distance between any two nodes of the graph across all epochs \n",
    "        # needs to be at least 50km to ensure a collision-free communications network\n",
    "        min_sat_d = self.get_sat_constraint(d_sat_min_ep) \n",
    "\n",
    "        # Additional information on the fitness of the input chromosome\n",
    "        if verbose:\n",
    "            print(100 * \"-\")\n",
    "            print(\"RESULTS:\")\n",
    "            print(\"Total number of satellites (W1: {}, W2: {}): {}\".format(N1, N2, N1+N2))\n",
    "            print(\"OBJECTIVE #1 - Average communications cost: {}\".format(f1/nf1))\n",
    "            print(\"OBJECTIVE #2 - Cost of infrastructure: {}\".format(f2/nf2))\n",
    "            print(\"CONSTRAINT - Minimum distance between rovers ({}): {} km\".format(\"NOK\" if min_rover_d > 0 else \"OK\", d_rover_min))\n",
    "            print(\"CONSTRAINT - Minimum distance between sats ({}): {} km\".format(\"NOK\" if min_sat_d > 0 else \"OK\", d_sat_min_ep))\n",
    "            print(100 * \"-\")\n",
    "        return [f1/nf1, f2/nf2, min_rover_d, min_sat_d]\n",
    "    \n",
    "    def pretty(self, x):\n",
    "        \"\"\"A verbose evaluation of the fitness functions\n",
    "\n",
    "        Args:\n",
    "            x (list): chromosome describing the New Mars communications infrastructure\n",
    "\n",
    "        Returns:\n",
    "            float: fitness for average shortest path\n",
    "            float: fitness for total number of satellites\n",
    "            float: constraint for rover positioning\n",
    "            float: constraint for satellite positioning\n",
    "        \"\"\"\n",
    "        f1, f2, c1, c2 = self.fitness(x, verbose=True)\n",
    "        return f1, f2, c1, c2\n",
    "\n",
    "    def example(self, verbose=False):\n",
    "        \"\"\"A random chromosome example for the constellation optimization\n",
    "\n",
    "        Returns:\n",
    "            list: a valid chromosome representing a possible constellation design\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"CHROMOSOME:\")\n",
    "            print(\"x = [a1, e1, i1, w1, eta1] + [a2, e2, i2, w2, eta2] + [S1, P1, F1] + [S2, P2, F2] + [r1, r2, r3, r4]\")\n",
    "            print(100 * \"-\")\n",
    "            print(\"a1: float representing the normalized semi-major axis of Walker1 satellite orbits (in km) [1.05,1.8]\")\n",
    "            print(\"e1: float representing the eccentricity [0, 0.1]\")\n",
    "            print(\"i1: float representing the inclination [0, pi]\")\n",
    "            print(\"w1: float representing the argument of the perigee [0, 2pi]\")\n",
    "            print(\"eta1: float defined as the quality indicator of satellites in the first walker constellation [0, 100]\")\n",
    "            print(100 * \"-\")\n",
    "            print(\"a2: float representing the normalized semi-major axis of Walker2 satellite orbits (in km) [2.0,3.5]\")\n",
    "            print(\"e2: float representing the eccentricity [0, 0.1]\")\n",
    "            print(\"i2: float representing the inclination [0, pi]\")\n",
    "            print(\"w2: float representing the argument of the perigee [0, 2pi]\")\n",
    "            print(\"eta2: float defined as the quality indicator of satellites in the first walker constellation [0, 100]\")\n",
    "            print(100 * \"-\")\n",
    "            print(\"S1: integer corresponding to the number of satellites per plane [4, 10]\")\n",
    "            print(\"P1: integer corresponding to the number of planes [2, 10]\")\n",
    "            print(\"F1: integer defining the phasing of the constellation [0, 9]\")\n",
    "            print(100 * \"-\")\n",
    "            print(\"S2: integer corresponding to the number of satellites per plane [4, 10]\")\n",
    "            print(\"P2: integer corresponding to the number of planes [2, 10]\")\n",
    "            print(\"F2: integer defining the phasing of the constellation [0, 9]\")\n",
    "            print(100 * \"-\")\n",
    "            print(\"r1: index of rover 1 [0, 99]\")\n",
    "            print(\"r2: index of rover 2 [0, 99]\")\n",
    "            print(\"r3: index of rover 3 [0, 99]\")\n",
    "            print(\"r4: index of rover 4 [0, 99]\")\n",
    "            print(100 * \"-\")\n",
    "\n",
    "        return [1.8, 0.0, 1.2, 0.0, 55.0] + [2.3, 0.0, 1.2, 0.0, 15.0] + [10, 2, 1] + [10, 2, 1] + [13, 21, 34, 55]\n",
    "    \n",
    "    def compute_orbit_walker(self, walker, ep0, sma):\n",
    "        \"\"\"Compute one full-orbit of the Walker constellation planes (for plots)\n",
    "\n",
    "        Args:\n",
    "            walker (sgp4.SatrecArray): the array of Walker satellites to plot\n",
    "            ep0 (float): Julian date denoting starting epoch\n",
    "            sma (float): semi-major axis of orbit\n",
    "\n",
    "        Returns:\n",
    "            pos (numpy array, P x N x 3): N orbital x, y, z positions for P planes\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract mean motion\n",
    "        mean_motion = np.sqrt(pk.MU_EARTH / sma**3 / pk.EARTH_RADIUS**3) * 24 * 60 * 60 / (2 * np.pi)\n",
    "        # Compute time range for one full orbit\n",
    "        jds = np.linspace(ep0, ep0 + 1 / mean_motion, 100)\n",
    "        frs = jds * 0.0\n",
    "        # Propagate using SGP4\n",
    "        err, pos, _ = walker.sgp4(jds, frs)\n",
    "        if not np.all(err == 0):\n",
    "            raise ValueError(\"The satellite cannot be propagated successfully on the defined time grid\")\n",
    "        \n",
    "        return pos\n",
    "    \n",
    "    def compute_orbit_motherships(self, ep0):\n",
    "        \"\"\"Compute one full-orbit of the motherships from epoch ep0 (for plots)\n",
    "\n",
    "        Args:\n",
    "            ep0 (float): Julian date denoting starting epoch\n",
    "\n",
    "        Returns:\n",
    "            orbits (numpy array, S x N x 3): N orbital x, y, z positions for S satellites\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pre-allocate return array\n",
    "        N = 100 # number of samples along orbit\n",
    "        # Get SGP4-ready motherships\n",
    "        motherships = get_mothership_satellites()\n",
    "        orbits = np.zeros((len(motherships), N, 3))\n",
    "        for i, usr in enumerate(motherships):\n",
    "            # Extract mean motion\n",
    "            mean_motion = usr.no_kozai * 24 * 60 / (2 * np.pi) # revolutions per day\n",
    "            # Compute time range for one full orbit\n",
    "            jds = np.linspace(ep0, ep0 + 1 / mean_motion, N)\n",
    "            frs = jds * 0.0\n",
    "            # Propagate using SGP4\n",
    "            err, pos, _ = usr.sgp4_array(jds, frs)\n",
    "            if not np.all(err == 0):\n",
    "                raise ValueError(\"The satellite cannot be propagated successfully on the defined time grid\")\n",
    "            orbits[i] = pos\n",
    "        \n",
    "        return orbits\n",
    "    \n",
    "    def plot(self, x, src, dst, ep=1, lims=10000, ax=None, dark_mode=True):\n",
    "        \"\"\"Plot the full constellations with solution path and optional orbits\n",
    "\n",
    "        Args:\n",
    "            x (list): chromosome describing the communications network\n",
    "            src (int): mothership index denoting path source\n",
    "            dst (int): rover index denoting path destination\n",
    "            ep (int): index of the epoch in the predefined time grid\n",
    "            lims (float, optional): plot limits. Defaults to 10000.\n",
    "            ax (matplotlib 3D axis, optional): plot axis.\n",
    "            dark_mode (bool, optional): dark background for plot (recommended)\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.axis: the 3D plot axes\n",
    "            list: indices of the graph nodes on the communications path (if one is found, otherwise [])\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create the plotting axis if needed\n",
    "        if ax is None:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "        # Apply a dark background for better visualization\n",
    "        if dark_mode:\n",
    "            sns.set(style=\"darkgrid\")\n",
    "            plt.style.use(\"dark_background\")\n",
    "            \n",
    "        # Construct the two Walker constellations from the specifications \n",
    "        walker1, walker2 = self.construct_walkers(x)\n",
    "        # Construct the rover positions\n",
    "        rovers_idx = np.array(x[-4:]).astype(int)\n",
    "        lambda0 = self.lambdas[rovers_idx]\n",
    "        phi0 = self.phis[rovers_idx]\n",
    "        rovers = construct_rover_pos(lambda0, phi0, self.n_rovers, self.jds, self.R_p, self.w_p)\n",
    "        # Construct the Walker satellite positions\n",
    "        pos = self.construct_pos(walker1, walker2, rovers)\n",
    "        # Compute and plot the orbits of the Walker and mothership satellites at the epoch ep\n",
    "        # Walker 1\n",
    "        N1 = x[10] * x[11]\n",
    "        w1_orb = self.compute_orbit_walker(walker1, self.jds[ep], x[0])\n",
    "        for i in range(N1):\n",
    "            ax.plot(w1_orb[i, :, 0], w1_orb[i, :, 1], w1_orb[i, :, 2], 'r-', linewidth=0.5)\n",
    "        # Walker 2\n",
    "        N2 = x[13] * x[14]\n",
    "        w2_orb = self.compute_orbit_walker(walker2, self.jds[ep], x[5])\n",
    "        for i in range(N2):\n",
    "            ax.plot(w2_orb[i, :, 0], w2_orb[i, :, 1], w2_orb[i, :, 2], 'b-', linewidth=0.5)\n",
    "        # Motherships\n",
    "        mothership_orb = self.compute_orbit_motherships(self.jds[ep])\n",
    "        for i in range(len(mothership_orb)):\n",
    "            ax.plot(mothership_orb[i, :, 0], mothership_orb[i, :, 1], mothership_orb[i, :, 2], 'w-', linewidth=0.5)\n",
    "\n",
    "        # Overlay the Walker satellite and mothership positions at epoch ep \n",
    "        # Walker1: red, Walker2: blue, motherships: white, rovers: yellow\n",
    "        ax.scatter(pos[:len(walker1),ep,0], pos[:len(walker1),ep,1], pos[:len(walker1),ep,2], c='r', marker=\"1\", s=200)\n",
    "        ax.scatter(pos[len(walker1):-self.n_motherships-self.n_rovers,ep,0], pos[len(walker1):-self.n_motherships-self.n_rovers,ep,1], pos[len(walker1):-self.n_motherships-self.n_rovers,ep,2], c='b', marker=\"1\", s=200)\n",
    "        ax.scatter(pos[-self.n_motherships-self.n_rovers:-self.n_rovers,ep,0], pos[-self.n_motherships-self.n_rovers:-self.n_rovers,ep,1], pos[-self.n_motherships-self.n_rovers:-self.n_rovers,ep,2], c='w', marker=\"1\", s=300)\n",
    "        # Annotate source nodes (motherships)\n",
    "        for i in range(self.n_motherships):\n",
    "            ax.text(pos[-self.n_motherships-self.n_rovers+i,ep,0], pos[-self.n_motherships-self.n_rovers+i,ep,1], pos[-self.n_motherships-self.n_rovers+i,ep,2],  '%s' % (str(i+1)), size=20, zorder=1,  color='w')         \n",
    "        \n",
    "        # Annotate destination nodes (rovers)\n",
    "        ax.scatter(pos[-self.n_rovers:,ep,0], pos[-self.n_rovers:,ep,1], pos[-self.n_rovers:,ep,2], c='y', marker=\"^\", s=200)\n",
    "        for i in range(self.n_rovers):\n",
    "            ax.text(pos[-self.n_rovers+i,ep,0], pos[-self.n_rovers+i,ep,1], pos[-self.n_rovers+i,ep,2],  '%s' % (str(i+1)), size=20, zorder=1,  color='y') \n",
    "\n",
    "        # Build the communications network\n",
    "        path = []\n",
    "        eta1, eta2 = x[4], x[9]\n",
    "        G, _, _ = self.build_graph(ep, pos, N1, (eta1, eta2))\n",
    "        N = len(G)\n",
    "        src_node = N1 + N2 + src - 1\n",
    "        dst_node = N1 + N2 + self.n_motherships + dst - 1\n",
    "        # Find the shortest path (if one exists)\n",
    "        try:\n",
    "            path = nx.shortest_path(G, src_node, dst_node, weight=\"weight\", method=\"dijkstra\")\n",
    "            for i,j in zip(path[:-1], path[1:]):\n",
    "                ax.plot([pos[i,ep,0], pos[j,ep,0]], [pos[i,ep,1], pos[j,ep,1]], [pos[i,ep,2], pos[j,ep,2]], 'g-.', linewidth=3)\n",
    "            print(\"Mothership {} (node {}) communicates with rover {} (node {}) at epoch {} via: {}\".format(\\\n",
    "                src, src_node, dst,  dst_node, ep, path))\n",
    "        except nx.exception.NetworkXNoPath as e:\n",
    "            print(\"Mothership {} (node {}) cannot reach rover {} (node {}) at epoch {}\".format(\\\n",
    "                src, src_node, dst,  dst_node, ep))\n",
    "\n",
    "        # Plot the New Mars planet\n",
    "        r = pk.EARTH_RADIUS/1000\n",
    "        u, v = np.mgrid[0:2 * np.pi:30j, 0:np.pi:20j]\n",
    "        x = r * np.cos(u) * np.sin(v)\n",
    "        y = r * np.sin(u) * np.sin(v)\n",
    "        z = r * np.cos(v)\n",
    "        ax.plot_surface(x, y, z, alpha=0.3, color=\"purple\", linewidth=0)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_xlim(-lims,lims)\n",
    "        ax.set_ylim(-lims,lims)\n",
    "        ax.set_zlim(-lims,lims)\n",
    "        ax.set_box_aspect([ub - lb for lb, ub in (getattr(ax, f'get_{a}lim')() for a in 'xyz')])\n",
    "        return ax, path\n",
    "\n",
    "def combine_scores(points):\n",
    "    \"\"\" Function for aggregating single solutions into one score using hypervolume indicator \"\"\"\n",
    "\n",
    "    ref_point = np.array([1.2, 1.4])\n",
    "    \n",
    "    # solutions that not dominate the reference point are excluded\n",
    "    filtered_points = [s[:2] for s in points if pg.pareto_dominance(s[:2], ref_point)]\n",
    "    \n",
    "    if len(filtered_points) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        hv = pg.hypervolume(filtered_points)\n",
    "        #return -hv.computborderse(ref_point) * 10000\n",
    "        return -hv.compute(ref_point) * 10000\n",
    "\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from fcmaes.optimizer import wrapper, dtime, Bite_cpp, De_cpp, Crfmnes_cpp\n",
    "import fcmaes\n",
    "from fcmaes import retry, mode, modecpp, moretry, mapelites, diversifier\n",
    "from scipy.optimize import Bounds    \n",
    "from os import walk\n",
    "import multiprocessing as mp\n",
    "import ctypes as ct\n",
    "from functools import partial\n",
    "from fcmaes import bitecpp\n",
    "from multiprocessing import Manager\n",
    "\n",
    "udp = constellation_udp() \n",
    "nobj = 2\n",
    "ncon = 2\n",
    "dim = 20\n",
    "ref_point = np.array([1.2, 1.4])\n",
    "ubs = udp.get_bounds()\n",
    "bounds = Bounds(ubs[0], ubs[1]) \n",
    "    \n",
    "def fitness(x): # fitness wrapper converting the last ten arguments into integer values\n",
    "    x[10:] = x[10:].astype(int)\n",
    "    return np.array(udp.fitness(x))\n",
    "\n",
    "def select_valid(xs, ys):\n",
    "    cv = np.array([np.amax(y[nobj:], 0) for y in ys])\n",
    "    valid = (cv <= 0)\n",
    "    ys = ys.T[:nobj].T\n",
    "    ys = ys[valid]\n",
    "    xs = xs[valid]                        \n",
    "    xs, ys = moretry.pareto(xs, ys)\n",
    "    return xs, ys\n",
    "\n",
    "def read_solution(fname):\n",
    "    with np.load(fname) as data:\n",
    "        xs = data['xs']\n",
    "        ys = data['ys']                      \n",
    "    return xs, ys\n",
    "\n",
    "from fcmaes.evaluator import parallel_mo\n",
    "\n",
    "#+++++++ Apply fcmaes multi objective optimization using NSGA-II population update ++++++++++++++++++++++++\n",
    "# Uses fcmaes multi objective optimization to optimize the pareto front\n",
    "# Uses parallel function evaluation, but cannot pass score 6400 even when executed many times, \n",
    "# using a large number of iterations and a big population. \n",
    "# Which is the reason only one team - \"ML Actonauts\" achieved this goal during the GECCO competition \n",
    "# https://www.esa.int/gsp/ACT/projects/spoc-2023/ \n",
    "\n",
    "def mo_par():\n",
    "            \n",
    "    guess = None\n",
    "    #guess, _ = read_solution(\"res/quantcomm_1_100_6372134.npz\") # inject an existing pareto front   \n",
    "    popsize = 500\n",
    "\n",
    "    es = mode.MODE(nobj, ncon, bounds, popsize = popsize, nsga_update=True) # Python MOO optimizer\n",
    "    #es = modecpp.MODE_C(nobj, ncon, bounds, popsize = popsize, nsga_update=True) # C++ MOO optimizer\n",
    "   \n",
    "    fit = parallel_mo(fitness, nobj+ncon, workers = mp.cpu_count())\n",
    "    iters = 0\n",
    "    stop = 0\n",
    "    max_hv = 0\n",
    "    time_0 = time.perf_counter()\n",
    "    if not guess is None:\n",
    "        es.set_guess(guess, fitness)\n",
    "\n",
    "    while stop == 0 and iters < 2500:               \n",
    "        xs = es.ask()\n",
    "        ys = fit(xs)        \n",
    "        es.tell(ys) # tell evaluated x             \n",
    "        iters += 1\n",
    "        valid = [y[:2] for y in ys if np.less_equal(y , np.array([1.2, 1.4, 0, 0])).all()]\n",
    "        hv = pg.hypervolume(valid).compute(ref_point)\n",
    "        if hv > max_hv:\n",
    "            max_hv = hv\n",
    "        if hv > 0.9999*max_hv: # show stagnation\n",
    "            logger.info(f'time: {dtime(time_0)} iter: {iters} hv: {hv * 10000}')\n",
    "            np.savez_compressed(\"quantcomm_\" + str(int(hv * 1000000)), xs=xs, ys=ys)\n",
    "    fit.stop()\n",
    "    return xs, ys\n",
    "\n",
    "#+++++++ Apply fcmaes diversifier quality diversity algorithm ++++++++++++++++++++++++\n",
    "# The initial archive is created using an existing pareto front. This way the QD-algorithm\n",
    "# dosn't need to find this \"hard to reach\" area of the solution space by its own. \n",
    "\n",
    "def mo_to_qd(y):\n",
    "    f1, f2, c1, c2 = y\n",
    "    # weight the objectives and constraints\n",
    "    return f1/0.5 + f2/1.4 + c1/3000 + c2/50, \\\n",
    "                np.minimum(ref_point, np.array([f1, f2])) # use the objectives as descriptive space\n",
    "\n",
    "def qd_fun(x):\n",
    "    return mo_to_qd(fitness(x)) # convert the MO result into a QD result\n",
    "\n",
    "def get_arch(qd_bounds, niche_num, samples_per_niche):\n",
    "    xs, _ = read_solution(\"res/quantcomm_1_100_6372134.npz\") # inject an existing pareto front      \n",
    "    arch = mapelites.empty_archive(dim, qd_bounds, niche_num, samples_per_niche)\n",
    "    mapelites.update_archive(arch, xs, qd_fun)\n",
    "    return arch\n",
    "\n",
    "def nd_par(niche_num = 10000):\n",
    "    udp = constellation_udp()\n",
    "    ubs = udp.get_bounds()\n",
    "    qd_bounds = Bounds([0.7, 0.], [1.2, 1.4])\n",
    "    samples_per_niche = 20\n",
    "    arch = get_arch(qd_bounds, niche_num, samples_per_niche)\n",
    "    opt_params0 = {'solver':'elites', 'popsize':100, 'use':2}\n",
    "    opt_params1 = {'solver':'CRMFNES_CPP', 'max_evals':2000, 'popsize':32, 'stall_criterion':3}\n",
    "    archive = diversifier.minimize(\n",
    "         mapelites.wrapper(qd_fun, 2, interval=10000, save_interval=100000),\n",
    "         bounds, qd_bounds,\n",
    "         workers = 32, opt_params=[opt_params0, opt_params1], archive = arch,\n",
    "         niche_num = niche_num, samples_per_niche = samples_per_niche,\n",
    "         max_evals = 1000000)\n",
    "\n",
    "    print('final archive:', archive.info())\n",
    "    archive.save('final archive')\n",
    "    \n",
    "    \n",
    "#++++++++++++++++++++++ Apply BiteOpt Single-Objective Optimization ++++++++++++++++++++++++++++++++++++++++\n",
    "# Uses https://github.com/avaneev/biteopt applied to a fitness function maximizing the hypervolume\n",
    "# to find the best target_num solutions maximizing the pareto front\n",
    "# Easily surpasses score 6400 when given enough time. The final result needs to be reduced to 100 solutions. \n",
    "\n",
    "def so_par():\n",
    "\n",
    "    target_num = 512 # desired size of the pareto front  \n",
    "\n",
    "    # hypervolume replacing one solution of the pareto front  \n",
    "    def fit_hyper(i, ys, x):\n",
    "        y = fitness(x)\n",
    "        c = sum([10000 + c for c in y[2:] if c > 0])\n",
    "        if c > 0: # constraint violation\n",
    "            return c\n",
    "        if pg.pareto_dominance(y[:2], ref_point):           \n",
    "            ys[i] = y[:2]\n",
    "            return -pg.hypervolume(ys).compute(ref_point) * 10000  \n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # parallel optimization of the whole pareto front    \n",
    "    class OptSo(object):\n",
    "           \n",
    "        def __init__(self, \n",
    "                     max_evals,\n",
    "                     xs,\n",
    "                     ys\n",
    "                    ): \n",
    "            self.max_evals = max_evals  \n",
    "            self.manager = Manager()   \n",
    "            self.ys = self.manager.list(ys)\n",
    "            self.ys0 = list(ys)\n",
    "            self.xs = self.manager.list(xs)\n",
    "            self.min_ys = np.amin(ys, axis=0)\n",
    "            self.count = mp.RawValue(ct.c_int, 0) \n",
    "            self.mutex = mp.Lock() \n",
    "            self.n = len(ys)\n",
    "        \n",
    "        def incr(self):\n",
    "            with self.mutex:\n",
    "                next = self.count.value\n",
    "                self.count.value += 1\n",
    "                return next\n",
    "    \n",
    "        def eval(self, workers=mp.cpu_count()):\n",
    "            proc=[mp.Process(target=self.eval_loop) for pid in range(workers)]\n",
    "            [p.start() for p in proc]\n",
    "            [p.join() for p in proc]             \n",
    "            return np.array(self.xs), np.array(self.ys)\n",
    "        \n",
    "        def eval_loop(self):\n",
    "            while True:\n",
    "                i = self.incr()\n",
    "                if i >= self.n:\n",
    "                    return\n",
    "                logger.info(f'optimizing solution {i}')\n",
    "                fit = wrapper(partial(fit_hyper, i, list(self.ys)))\n",
    "                x0 = self.xs[i]                                \n",
    "                ret = bitecpp.minimize(fit, bounds, x0, max_evaluations = self.max_evals)\n",
    "                if ret.fun < 0: # no constraint violation?\n",
    "                    y = fitness(ret.x)[:2]\n",
    "                    self.ys[i] = y\n",
    "                    self.xs[i] = ret.x\n",
    "     \n",
    "    def opt_so(max_evals, xs, ys, workers=mp.cpu_count()):\n",
    "        eval = OptSo(max_evals, xs, ys)\n",
    "        return eval.eval(workers)\n",
    "    \n",
    "    max_evals = 2000    \n",
    "      \n",
    "    # random initialization\n",
    "    # rg = Generator(MT19937()) \n",
    "    # xs = [rg.uniform(ubs[0], ubs[1]) for _ in range(target_num)]\n",
    "    # ys = [ref_point-0.000001 for _ in range(target_num)]\n",
    "\n",
    "    # initialization with a given pareto front \n",
    "    xs, ys = read_solution(\"res/quantcomm_1_100_6372134.npz\") # inject an existing pareto front\n",
    "    \n",
    "    last_xs = []\n",
    "    last_ys = []\n",
    "    for i in range(1, 1000):\n",
    "        xs, ys = opt_so(max_evals, xs, ys)\n",
    "        xs, ys = moretry.pareto(np.array(list(xs) + last_xs), \n",
    "                                    np.array(list(ys) + last_ys))\n",
    "        if len(ys) > target_num:\n",
    "            xs, ys = reduce(xs, ys, target_num)        \n",
    "        hv = int(pg.hypervolume(ys).compute(ref_point) * 10000000)  \n",
    "\n",
    "        np.savez_compressed(\"quantcomm_\" + str(i) + \"_\" + str(len(ys)) + \"_\" \n",
    "                            + str(max_evals) + \"_\" + str(hv), xs=xs, ys=ys)\n",
    "        last_xs = list(xs)\n",
    "        last_ys = list(ys)\n",
    "        \n",
    "    return xs\n",
    "\n",
    "\n",
    "#++++++++++++++++++++++ Apply PYMOO NSGA-II ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Uses PYMOO and https://github.com/avaneev/biteopt to find the best target_num solutions\n",
    "# maximizing the pareto front.\n",
    "# Easily surpasses score 6400 when given enough time. The result is already reduced to 100 solutions. \n",
    "# Note that instead of relying on PYMOOs parallelization mechanisms (partial) optimization runs\n",
    "# are executed in parallel achieving maximal scaling with the number of cores. \n",
    "# The fitness function is \"hijacked\" collecting solutions later joined for the resulting pareto front.\n",
    "\n",
    "def pymoo_par():\n",
    "\n",
    "    from pymoo.core.problem import ElementwiseProblem \n",
    "    from pymoo.algorithms.moo.nsga2 import NSGA2 \n",
    "    from pymoo.termination import get_termination\n",
    "    from pymoo.operators.crossover.sbx import SBX\n",
    "    from pymoo.operators.mutation.pm import PM\n",
    "    from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "    from pymoo.constraints.eps import AdaptiveEpsilonConstraintHandling\n",
    "    from pymoo.optimize import minimize\n",
    "    from itertools import chain\n",
    "\n",
    "    target_num = 100 # desired size of the pareto front \n",
    "    n_eval = 10000\n",
    "    popsize = 300\n",
    "    time_0 = time.perf_counter()\n",
    "    guess = None\n",
    "    guess, ys = read_solution(\"res/quantcomm_1_100_6372134.npz\") # inject an existing pareto front\n",
    "    guess, ys = reduce(guess, ys, target_num)   \n",
    "    \n",
    "    class fitness_wrapper():\n",
    "        \n",
    "        def __init__(self, \n",
    "                     pid,\n",
    "                     xs_out,\n",
    "                     ys_out\n",
    "                    ): \n",
    "            self.max_hv = 0\n",
    "            self.xs = []\n",
    "            self.ys = []\n",
    "            self.count = 1\n",
    "            self.evals = 0\n",
    "            self.pid = pid\n",
    "            self.xs_out = xs_out\n",
    "            self.ys_out = ys_out\n",
    "        \n",
    "        # fitness accumulates valid solutions and monitors their hypervolume\n",
    "        def __call__(self, x):\n",
    "            y = fitness(x)\n",
    "            self.evals += 1    \n",
    "            if np.amax(y[2:]) <= 0 and np.less_equal(y[:2], ref_point).all() : # add only valid solutions\n",
    "                self.ys.append(y[:2]) # exclude constraint values because solution is valid\n",
    "                self.xs.append(x)\n",
    "            if len(self.ys) >= 2*popsize:\n",
    "                self.count += 1      \n",
    "                xs, ys = moretry.pareto(np.array(self.xs), np.array(self.ys)) # reduce to pareto front\n",
    "                self.xs, self.ys = list(xs), list(ys)\n",
    "                hv = pg.hypervolume(self.ys).compute(ref_point)\n",
    "                if hv > self.max_hv * 1.0001: # significant improvement: register solutions at managed dicts\n",
    "                    self.max_hv = hv\n",
    "                    self.xs_out[self.pid] = self.xs\n",
    "                    self.ys_out[self.pid] = self.ys\n",
    "                    logger.info(f'time: {dtime(time_0)} ev: {self.evals} hv: {hv * 10000} n: {len(ys)}')\n",
    "            return y    \n",
    "      \n",
    "    class OptPymoo(object):\n",
    "        \n",
    "        def eval_loop(self, workers=mp.cpu_count()):\n",
    "            xs = guess\n",
    "            for i in range(1, 1000):\n",
    "                xs, ys = self.eval(i, xs, workers)\n",
    "            return xs, ys\n",
    "            \n",
    "        def eval(self, i, guess, workers):\n",
    "            manager = Manager()\n",
    "            xs_out = manager.dict() # for inter process communication\n",
    "            ys_out = manager.dict() # collects solutions generated in the sub processes\n",
    "            fits = [fitness_wrapper(pid, xs_out, ys_out) for pid in range(workers)]\n",
    "            proc=[mp.Process(target=self.optimize, args=(guess, fits[pid], pid)) for pid in range(workers)]\n",
    "            [p.start() for p in proc] # spawn NSGAII optimization workers\n",
    "            [p.join() for p in proc]    \n",
    "            xs = np.array(list(chain.from_iterable(xs_out.values()))) # join collected solutions\n",
    "            ys = np.array(list(chain.from_iterable(ys_out.values()))) # we ignore the pymoo optimization result\n",
    "            xs, ys = moretry.pareto(xs, ys)\n",
    "            if len(ys) > target_num:\n",
    "                xs, ys = reduce(xs, ys, target_num)        \n",
    "            hv = int(pg.hypervolume(ys).compute(ref_point) * 10000000)  \n",
    "            np.savez_compressed(\"quantcomm_\" + str(i) + \"_\" + str(len(ys)) + \n",
    "                                \"_\" + str(hv), xs=xs, ys=ys)       \n",
    "            return xs, ys\n",
    "        \n",
    "        def optimize(self, guess, fit, pid):\n",
    "            \n",
    "            class MyProblem(ElementwiseProblem):\n",
    "    \n",
    "                def __init__(self, **kwargs):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
    "                    super().__init__(n_var=dim,\n",
    "                                     n_obj=nobj,\n",
    "                                     n_constr=ncon,\n",
    "                                     xl=np.array(bounds.lb),\n",
    "                                     xu=np.array(bounds.ub), **kwargs)\n",
    "            \n",
    "                def _evaluate(self, x, out, *args, **kwargs):   \n",
    "                    y = fit(x)\n",
    "                    out[\"F\"] = y[:nobj]\n",
    "                    out[\"G\"] = y[nobj:]\n",
    "\n",
    "            problem = MyProblem()\n",
    "            algorithm = NSGA2(\n",
    "                pop_size=popsize,\n",
    "                n_offsprings=10,\n",
    "                sampling=FloatRandomSampling() if guess is None else guess,\n",
    "                crossover=SBX(prob=0.9, eta=15), # simulated binary crossover\n",
    "                mutation=PM(eta=20), # polynomial mutation     \n",
    "                eliminate_duplicates=True,\n",
    "            )    \n",
    "            algorithm = AdaptiveEpsilonConstraintHandling(algorithm, perc_eps_until=0.5)        \n",
    "            minimize(problem, algorithm, get_termination(\"n_eval\", n_eval), verbose=False, seed=pid*677)\n",
    "    \n",
    "    opt = OptPymoo()\n",
    "    return opt.eval_loop()\n",
    "\n",
    "#++++++++++++++++++++++ Reduction to 100 solutions ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Uses https://github.com/avaneev/biteopt / parallel optimization to find the best num solutions\n",
    "# maximizing the pareto front\n",
    "   \n",
    "def reduce(xs, ys, num, evals = 50000, retries = mp.cpu_count()): \n",
    "    if len(ys) <= num:\n",
    "        return xs, ys\n",
    "    bounds = Bounds([0]*num, [len(ys)-1E-9]*num) # select best num from xs, ys\n",
    "    \n",
    "    def fit(x): # selects 100 solutions and returns the negated pareto front of this selection\n",
    "        selected = x.astype(int) \n",
    "        ys_sel = ys[selected]      \n",
    "        hv = pg.hypervolume(ys_sel)\n",
    "        return -hv.compute(ref_point) * 10000\n",
    "\n",
    "    res = fcmaes.retry.minimize(wrapper(fit), # parallel optimization restart / retry\n",
    "                         bounds, \n",
    "                         optimizer=Bite_cpp(evals), \n",
    "                         num_retries=retries)\n",
    "    \n",
    "    selected = res.x.astype(int)\n",
    "    return xs[selected], ys[selected]\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #pymoo_par()\n",
    "    #so_par()    \n",
    "    mo_par()\n",
    "    #nd_par()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8774e-66aa-48e4-81ec-6de6f1cf2b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
